{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a059fec",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a06547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# sklearn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "RunGeneticAlgo = False\n",
    "level = 'cm'\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "localpath = '/Users/havardhegre/Pickles/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64093b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_modelname_test = level + '_' + 'ensemble_genetic' + '_test'\n",
    "\n",
    "ensemble_test_df = pd.DataFrame.forecasts.read_store(stored_modelname_test, run=run_id)\n",
    "ensemble_test_df.replace([np.inf, -np.inf], 0, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise QS\n",
    "   \n",
    "Fatality_cutoff = 10\n",
    "Time_cutoff = 12\n",
    "history_colname = \"ts_ged_sb_f\" + str(Fatality_cutoff) + \"_t\" + str(Time_cutoff)\n",
    "\n",
    "queryset = Queryset(\"fatalities_history\", \"country_month\")\n",
    "    # target variable\n",
    "queryset = queryset.with_column(Column(\"ln_ged_sb_dep\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "                 .transform.ops.ln()\n",
    "                 .transform.missing.fill()\n",
    "                )   \n",
    "queryset = queryset.with_column(Column(history_colname, from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")             \n",
    "             .transform.missing.replace_na()\n",
    "             .transform.bool.gte(Fatality_cutoff)\n",
    "             .transform.temporal.time_since()\n",
    "             .transform.missing.replace_na()\n",
    "             .transform.bool.gte(Time_cutoff)\n",
    "                               )\n",
    "history_df = queryset.publish().fetch()\n",
    "history_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: assumption is that panels are balanced!\n",
    "NumberOfMonths = 48\n",
    "for step in steps:\n",
    "    colname = history_colname + '_s' + str(step)\n",
    "    fromdate = test_partitioner_dict['predict'][0] - step\n",
    "    todate = test_partitioner_dict['predict'][1] - step\n",
    "#    print(step, fromdate, todate, colname)\n",
    "    ensemble_test_df[colname] = history_df[history_colname].loc[fromdate:todate]\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = history_colname + '_s3'\n",
    "print(ensemble_test_df[colname].value_counts())\n",
    "grouped = ensemble_test_df.groupby(colname)\n",
    "percentiles = (0.25,0.5,0.75,0.90,0.95,0.98,0.99,0.995)\n",
    "for name, group in grouped:\n",
    "    print(name)\n",
    "    print(group['ln_ged_sb_dep'].describe(percentiles = percentiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df[['decay_ged_sb_5','history_class']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_results = [] # list to hold evaluation results\n",
    "\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    col = 'step_pred_' + str(step)\n",
    "    mse_test_all = mean_squared_error(ensemble_test_df[col], ensemble_test_df['ln_ged_sb_dep'])\n",
    "    colname = history_colname + '_s' + str(step)\n",
    "    print(ensemble_test_df[colname].value_counts())\n",
    "    grouped_dfs = ensemble_test_df.groupby(colname)\n",
    "    percentiles = (0.25,0.5,0.75,0.90,0.95,0.98,0.99,0.995)\n",
    "    for name, group in grouped_dfs:\n",
    "        if name == 1:\n",
    "            mse_test_lowconflict = mean_squared_error(group[col], group['ln_ged_sb_dep'])\n",
    "#            print('0', name, mse_lowconflict)\n",
    "        if name == 0:\n",
    "            mse_test_highconflict = mean_squared_error(group[col], group['ln_ged_sb_dep'])\n",
    "#            print(name)\n",
    "#    print(col, mse_test_all, mse_lowconflict, mse_highconflict)\n",
    "    Results = {\n",
    "        'MSE_all':  mse_test_all,\n",
    "        'RMSE_all': np.sqrt(mse_test_all),\n",
    "        'MSE_lowconflict':  mse_test_lowconflict,\n",
    "        'RMSE_lowconflict': np.sqrt(mse_test_lowconflict),\n",
    "        'MSE_highconflict':  mse_test_highconflict,\n",
    "        'RMSE_highconflict': np.sqrt(mse_test_highconflict),\n",
    "    }\n",
    "    Evaluation_results.append(Results)\n",
    "\n",
    "Evaluation_results_df = pd.DataFrame(Evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
