{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c567d3bf",
   "metadata": {},
   "source": [
    "# Notebook to define ensemble for production, cm level\n",
    "Version developed for ViEWS monthly updates: Fatalities003\n",
    "## Including ensemble weighting\n",
    "\n",
    "This notebook defines the ensemble used for production: selects a set of pre-trained models, retrieves and calibrates them, computes weights, and computes and stores the ensemble model predictions.\n",
    "\n",
    "Models are stored in model storage and most of them specified in the notebook fat_cm_constituentmodels\n",
    "\n",
    "The notebook draws on the following files in this repository:\n",
    "\n",
    "Script file: \n",
    "    Ensembling.py\n",
    "    FetchData.py\n",
    "\n",
    "Lists of models:\n",
    "    ModelList_cm_{dev_id}.csv (not yet functional)\n",
    "    List of pickles at local directory (will rewrite to drop dependence on this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ce4c622759398",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Note\n",
    "### Numbers in the models 11, 12, 13 are log values even if the column for model 12, 13 is ged_sb_dep\n",
    "### Not sure whether the calibrated ensemble model should go through the calibration function or ensembling the calibrated models.\n",
    "### There are negative values after calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Views 3\n",
    "import views_runs\n",
    "# import views_dataviz\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Other packages\n",
    "import getpass\n",
    "import copy\n",
    "from pathlib import Path\n",
    "# pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "# Packages from this repository, Tools folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "import os\n",
    "\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions\n",
    "\n",
    "from ViewsEstimators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89992da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities003'\n",
    "run_id = 'Fatalities003'\n",
    "EndOfHistory = 509\n",
    "RunGeneticAlgo = True\n",
    "level = 'cm'\n",
    "get_future = False\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "localpath = f'/Users/{username}/Pickles/'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/VIEWS documentation {dev_id}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec1bfa",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, dev_id, level, get_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fa9a4bca6b51d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ModelList[11]['predictions_calib_df'] = ModelList[11]['predictions_calib_df'].applymap(lambda x: np.exp(x) - 1)\n",
    "ModelList[11]['predictions_calib_df'].rename(columns={'ln_ged_sb_dep':'ged_sb_dep'}, inplace=True)\n",
    "ModelList[11]['predictions_test_df'] = ModelList[11]['predictions_test_df'].applymap(lambda x: np.exp(x) - 1)\n",
    "ModelList[11]['predictions_test_df'].rename(columns={'ln_ged_sb_dep':'ged_sb_dep'}, inplace=True)\n",
    "\n",
    "ModelList[12]['predictions_calib_df'] = ModelList[12]['predictions_calib_df'].applymap(lambda x: np.exp(x) - 1)\n",
    "ModelList[12]['predictions_test_df'] = ModelList[12]['predictions_test_df'].applymap(lambda x: np.exp(x) - 1)\n",
    "\n",
    "ModelList[13]['predictions_calib_df'] = ModelList[13]['predictions_calib_df'].applymap(lambda x: np.exp(x) - 1)\n",
    "ModelList[13]['predictions_test_df'] = ModelList[13]['predictions_test_df'].applymap(lambda x: np.exp(x) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef4baa73dd26e5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Create ensemble model using equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edf0fe46d3a6b2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfs_calib = [model['predictions_calib_df'] for model in ModelList]\n",
    "dfs_test = [model['predictions_test_df'] for model in ModelList]\n",
    "weight = 1/15\n",
    "ensemble_df_calib = pd.concat(dfs_calib, axis=1)\n",
    "ensemble_df_test = pd.concat(dfs_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523f5738f11b0bd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ensemble_df_calib['ensemble_ged_sb_dep'] = weight * sum([df.iloc[:, 0] for df in dfs_calib])\n",
    "ensemble_df_test['ensemble_ged_sb_dep'] = weight * sum([df.iloc[:, 0] for df in dfs_test])\n",
    "\n",
    "for i in range(1, 37):\n",
    "    ensemble_df_calib[f'ensemble_step_pred_{i}'] = weight * sum([df.iloc[:, i] for df in dfs_calib])\n",
    "ensemble_df_calib.drop(ensemble_df_calib.columns[:37], axis=1, inplace=True)\n",
    "cols = ModelList[0]['predictions_calib_df'].columns\n",
    "ensemble_df_calib.columns = cols\n",
    "\n",
    "for i in range(1, 37):\n",
    "    ensemble_df_test[f'ensemble_step_pred_{i}'] = weight * sum([df.iloc[:, i] for df in dfs_test])\n",
    "ensemble_df_test.drop(ensemble_df_test.columns[:37], axis=1, inplace=True)\n",
    "cols = ModelList[0]['predictions_test_df'].columns\n",
    "ensemble_df_test.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0ef0a28b2acbe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ModelList.append({'modelname': 'ensemble', 'predictions_calib_df': ensemble_df_calib, 'predictions_test_df': ensemble_df_test})\n",
    "ModelList = CalibratePredictions(ModelList, steps, EndOfHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc758ee619bbb3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ee08f61caa7e4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_calib_cor_matrix = []\n",
    "model_test_cor_matrix = []\n",
    "for model in ModelList:\n",
    "    model_calib_cor_matrix.append((model['predictions_calib_df'].iloc[:, 1:-1]).corr())\n",
    "    model_test_cor_matrix.append((model['predictions_test_df'].iloc[:, 1:-1]).corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b6358e89871d8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb557f5c95bc5dd7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_step_rmse(ModelList, prediction_df):\n",
    "    pred_cols = [f'step_pred_{str(i)}' for i in steps] \n",
    "    step_rmse = {col:[] for col in pred_cols}\n",
    "    for model in ModelList:      \n",
    "        df = model[prediction_df]\n",
    "        for col in pred_cols:\n",
    "            mse = mean_squared_error(df['ged_sb_dep'], df[col])\n",
    "            step_rmse[col].append(np.sqrt(mse))\n",
    "    return pd.DataFrame(step_rmse)\n",
    "    \n",
    "def calculate_row_mse(ModelList, prediction_df):\n",
    "    for model in ModelList:\n",
    "        df = model[prediction_df]\n",
    "        pred_cols = [f'step_pred_{str(i)}' for i in steps]\n",
    "        df['mse'] = df.apply(lambda row: mean_squared_error([row['ged_sb_dep']] * 36, \n",
    "                            [row[col] for col in pred_cols]), axis=1)\n",
    "\n",
    "def get_model_rmse(ModelList, prediction_df):\n",
    "    model_rmse = {'model': [], 'rmse': []}\n",
    "    for model in ModelList:\n",
    "        name = model['modelname']\n",
    "        df = model[prediction_df]\n",
    "        model_rmse['model'].append(name)\n",
    "        model_rmse['rmse'].append(np.sqrt(df['mse'].mean()))\n",
    "    df_model_rmse = pd.DataFrame(model_rmse)\n",
    "    return df_model_rmse\n",
    "\n",
    "def get_top_10_cases(ModelList, prediction_df):\n",
    "    top_10_cases = {'model': [], 'month_id': [], 'country_id': [], 'rmse': []}\n",
    "    for model in ModelList:\n",
    "        name = model['modelname']\n",
    "        df = model[prediction_df]\n",
    "        df_sorted_model = df.sort_values(by=['mse'], ascending=False).head(10)\n",
    "        for _ in range(10):\n",
    "            top_10_cases['model'].append(name)\n",
    "        for month in df_sorted_model.index.get_level_values(level=0):\n",
    "            top_10_cases['month_id'].append(month)\n",
    "        for country in df_sorted_model.index.get_level_values(level=1):\n",
    "            top_10_cases['country_id'].append(country)  \n",
    "        for mse in df_sorted_model['mse']:\n",
    "            top_10_cases['rmse'].append(np.sqrt(mse))\n",
    "    pd_top_10_cases = pd.DataFrame(top_10_cases)\n",
    "    pd_top_10_cases.set_index('model', inplace=True)\n",
    "    return pd_top_10_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20fd432d262d46",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ModelList_eval = copy.deepcopy(ModelList)\n",
    "df_calib_step_rmse = calculate_step_rmse(ModelList_eval, 'predictions_calib_df')\n",
    "df_test_step_rmse = calculate_step_rmse(ModelList_eval, 'predictions_test_df')\n",
    "\n",
    "calculate_row_mse(ModelList_eval, 'predictions_calib_df')\n",
    "calculate_row_mse(ModelList_eval, 'predictions_test_df')\n",
    "calculate_row_mse(ModelList_eval, 'calib_df_cal_expand')\n",
    "calculate_row_mse(ModelList_eval, 'calib_df_cal_gam')\n",
    "calculate_row_mse(ModelList_eval, 'test_df_cal_expand')\n",
    "calculate_row_mse(ModelList_eval, 'test_df_cal_gam')\n",
    "\n",
    "# Calculate the rmse of each model\n",
    "df_calib_rmse = get_model_rmse(ModelList_eval, 'predictions_calib_df')\n",
    "df_calib_expand_rmse = get_model_rmse(ModelList_eval, 'calib_df_cal_expand')\n",
    "df_calib_gam_rmse = get_model_rmse(ModelList_eval, 'calib_df_cal_gam')\n",
    "\n",
    "df_test_rmse = get_model_rmse(ModelList_eval, 'predictions_test_df') \n",
    "df_test_expand_rmse = get_model_rmse(ModelList_eval, 'test_df_cal_expand')\n",
    "df_test_gam_rmse = get_model_rmse(ModelList_eval, 'test_df_cal_gam')\n",
    "\n",
    "# Get the sorted rmse of each model\n",
    "# df_calib_rmse_sorted = get_model_rmse(ModelList_eval, 'predictions_calib_df').sort_values(by=['rmse'])\n",
    "# df_calib_expand_rmse_sorted = get_model_rmse(ModelList_eval, 'calib_df_cal_expand').sort_values(by=['rmse'])\n",
    "# df_calib_gam_rmse_sorted = get_model_rmse(ModelList_eval, 'calib_df_cal_gam').sort_values(by=['rmse'])\n",
    " \n",
    "# df_test_rmse_sorted = get_model_rmse(ModelList_eval, 'predictions_test_df') \n",
    "# df_test_expand_rmse_sorted = get_model_rmse(ModelList_eval, 'test_df_cal_expand').sort_values(by=['rmse'])\n",
    "# df_test_gam_rmse_sorted = get_model_rmse(ModelList_eval, 'test_df_cal_gam').sort_values(by=['rmse'])\n",
    "\n",
    "# Get the top 10 cases for each model\n",
    "df_calib_top10 = get_top_10_cases(ModelList_eval, 'predictions_calib_df')\n",
    "df_calib_expand_top10 = get_top_10_cases(ModelList_eval, 'calib_df_cal_expand')\n",
    "df_calib_gam_top10 = get_top_10_cases(ModelList_eval, 'calib_df_cal_gam')\n",
    "\n",
    "df_test_top10 = get_top_10_cases(ModelList_eval, 'predictions_test_df')\n",
    "df_test_top10 = get_top_10_cases(ModelList_eval, 'test_df_cal_expand')\n",
    "df_test_top10 = get_top_10_cases(ModelList_eval, 'test_df_cal_gam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b580b75e2eef56b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i,model in enumerate(ModelList):\n",
    "    print(i, model['modelname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf30eb0ebd49f0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_calib_rmse.index, df_calib_rmse['rmse'], color='red', label='Uncalibrated')\n",
    "ax.plot(df_calib_expand_rmse.index, df_calib_expand_rmse['rmse'], color='blue', label='Calibrated (expand)')\n",
    "ax.plot(df_calib_gam_rmse.index, df_calib_gam_rmse['rmse'], color='orange', label='Calibrated (gam)')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xticks(range(0, 16))\n",
    "plt.title('df_calib')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f533c4c3b66d810",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_test_rmse.index, df_test_rmse['rmse'], color='red',label='Uncalibrated')\n",
    "ax.plot(df_test_expand_rmse.index, df_test_expand_rmse['rmse'], color='blue', label='Calibrated (expand)')\n",
    "ax.plot(df_test_gam_rmse.index, df_test_gam_rmse['rmse'], color='orange', label='Calibrated (gam)')\n",
    "ax.legend()\n",
    "ax.set_xticks(range(0, 16))\n",
    "plt.title('df_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25512f3bbf73a60a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Plot model prediction for each step and each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15599a9844bb0a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction_each_step(model, label):\n",
    "    if 'calib' in label.split('_'):\n",
    "        df_category = 'calib'\n",
    "    elif 'test' in label.split('_'):\n",
    "        df_category = 'test'\n",
    "    else: \n",
    "        raise ValueError('Wrong label.')\n",
    "        \n",
    "    if label.split('_')[-1] == 'expand':\n",
    "        calibrate = 'Expand'\n",
    "    elif label.split('_')[-1] == 'gam':\n",
    "        calibrate = 'GAM'\n",
    "    else:\n",
    "        calibrate = 'Uncalibrated'\n",
    "    df_step_sum = model[label].iloc[:, 1:].sum().reset_index()\n",
    "    df_step_sum.columns = ['step', 'sum']\n",
    "    name = model['modelname']\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(df_step_sum['step'], df_step_sum['sum'])\n",
    "    plt.xticks(df_step_sum['step'], np.arange(1, 37))\n",
    "    plt.xlabel('Step_prediction')\n",
    "    plt.ylabel('Sum of fatalities for each step')\n",
    "    plt.title(f'Sum of fatalities for each step ({name}, {calibrate})')\n",
    "    \n",
    "    savepath = Path(f'../Plots/step/{df_category}/{calibrate}')\n",
    "    savepath.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(savepath/f'{name}.jpg')\n",
    "    plt.close()\n",
    "\n",
    "def plot_prediction_each_month(model, label):\n",
    "    if 'calib' in label.split('_'):\n",
    "        df_category = 'calib'\n",
    "    elif 'test' in label.split('_'):\n",
    "        df_category = 'test'\n",
    "    else: \n",
    "        raise ValueError('Wrong label.')\n",
    "        \n",
    "    if label.split('_')[-1] == 'expand':\n",
    "        calibrate = 'Expand'\n",
    "    elif label.split('_')[-1] == 'gam':\n",
    "        calibrate = 'GAM'\n",
    "    else:\n",
    "        calibrate = 'Uncalibrated'\n",
    "    df_month_step_sum = model[label].iloc[:, 1:].groupby('month_id').sum()\n",
    "    df_month_sum = df_month_step_sum.sum(axis=1).reset_index()\n",
    "    df_month_sum.columns = ['month_id', 'sum']\n",
    "    name = model['modelname']\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.bar(df_month_sum['month_id'], df_month_sum['sum'])\n",
    "    plt.xticks(df_month_sum['month_id'], rotation=45)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Sum of fatalities for each month')\n",
    "    plt.title(f'Sum of fatalities for each month ({name}, {calibrate})')\n",
    "    \n",
    "    savepath = Path(f'../Plots/month/{df_category}/{calibrate}')\n",
    "    savepath.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(savepath/f'{name}.jpg')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203e564dd3b16d6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for model in ModelList:\n",
    "    for label in ['predictions_calib_df', 'calib_df_cal_expand', 'calib_df_cal_gam', 'predictions_test_df', 'test_df_cal_expand', 'test_df_cal_gam']:\n",
    "        plot_prediction_each_step(model, label)\n",
    "        plot_prediction_each_month(model, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb0465e6939c52",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b506bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
