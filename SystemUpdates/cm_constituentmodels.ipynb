{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1098f7cb",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 constituent models \n",
    "## ViEWS production system, cm level\n",
    "\n",
    "\n",
    "This notebook trains a set of regression models for use in the monthly updated ViEWS predicting fatalities ensemble\n",
    "\n",
    "The notebook does the following: \n",
    "1. Retrieves data through querysets and stores in DataSets, a list of dictionaries\n",
    "2. Specifies the metadata of a number of models, stores in ModelList, a list of dictionaries\n",
    "3. Trains the models in ModelList, stores the trained objects in model storage and prediction storage\n",
    "4. Saves part of ModelList as csv and the rest as pickles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f7cba",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8855fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef27dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFRegressor, XGBRFClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# Packages from viewsforecasting repository\n",
    "\n",
    "#from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "from FetchData import FetchData, RetrieveFromList, document_queryset, ReturnQsList, document_ensemble\n",
    "from ViewsEstimators import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300ea25",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c76adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/havardhegre1/mambaforge/envs/viewser:\n",
      "views-dataviz             0.9.0                    pypi_0    pypi\n",
      "views-forecasts           0.5.3                    pypi_0    pypi\n",
      "views-mapper2             1.9.0                    pypi_0    pypi\n",
      "views-partitioning        3.0.1                    pypi_0    pypi\n",
      "views-runs                1.13.1                   pypi_0    pypi\n",
      "views-schema              2.3.0                    pypi_0    pypi\n",
      "views-storage             1.1.4                    pypi_0    pypi\n",
      "views-transformation-library 2.4.1                    pypi_0    pypi\n",
      "viewser                   5.13.0                   pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "!conda list | grep views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fdc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "# find out why and where missingness occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ae8aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Mydropbox to /Users/havardhegre1/Dropbox (ViEWS)/ViEWS\n",
      "User: havardhegre1\n",
      "Overleaf path set to /Users/havardhegre1/Dropbox (ViEWS)/Apps/Overleaf/VIEWS documentation Fatalities003/\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "dev_id = 'Fatalities003'\n",
    "run_id = dev_id\n",
    "\n",
    "# Generating a new run if necessary\n",
    "\n",
    "#try:\n",
    "#    ViewsMetadata().new_run(name=run_id,description='Developing the fatalities model for FCDO',min_month=1,max_month=999)\n",
    "#except KeyError:\n",
    "#    if 'devel' not in run_id:\n",
    "#        warnings.warn('You are overwriting a production system')\n",
    "\n",
    "RerunQuerysets = True\n",
    "\n",
    "FutureStart = 508\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,3,6,12,36]\n",
    "#fi_steps = [1,3,6,12,36]\n",
    "\n",
    "# Specifying partitions\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "username = os.getlogin()\n",
    "Mydropbox = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/VIEWS documentation {dev_id}/'\n",
    "print('Setting Mydropbox to',Mydropbox)\n",
    "\n",
    "print('User:', username)\n",
    "print('Overleaf path set to',overleafpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf0208",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a457b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    fatalities003_baseline; A dataset with 6 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_baseline_nonlog; A dataset with 6 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_topics_stub; A dataset with 62 columns, with data between t 1 and 852. (213 units)\n",
      "fatalities003_aquastat_stub; A dataset with 62 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_cm_conflict_history_stub; A dataset with 24 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_cm_conflict_history_ext; A dataset with 33 columns, with data between t = 1 and 852. (213 units)\n",
      " .    fatalities003_vdem_short_stub; A dataset with 57 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_wdi_short_stub; A dataset with 26 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_joint_narrow; A dataset with 39 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_joint_broad_stub; A dataset with 102 columns, with data between t 1 and 852. (213 units)\n",
      "fatalities003_faostat_stub;A dataset with 102 columns, with data between t 1 and 852. (213 units)\n",
      "fatalities003_faoprices_stub;A dataset with 102 columns, with data between t 1 and 852. (213 units)\n",
      " .    fatalities003_imfweo_stub;A dataset with 5 columns, with data between t 1 and 852. (213 units)\n",
      " .     .     .     .     .     .     .     .     .    Model:  fatalities003_baseline\n",
      "Model:  fatalities003_topics\n",
      "Model:  fatalities003_conflict_history\n",
      "Model:  fatalities003_conflict_history_nonlog\n",
      "Model:  fatalities003_conflict_history_long\n",
      "Model:  fatalities003_vdem_short\n",
      "Model:  fatalities003_wdi_short\n",
      "Model:  fatalities003_all_features\n",
      "Model:  fatalities003_joint_narrow\n",
      "Model:  fatalities003_joint_broad\n",
      "Model:  fatalities003_joint_broad_nonlog\n",
      "Model:  fatalities003_imfweo\n"
     ]
    }
   ],
   "source": [
    "# Create Markdown documentation of all querysets used\n",
    "level = 'cm'\n",
    "qslist = ReturnQsList(level)\n",
    "document_queryset(qslist,dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5cde4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedFirstSplitRegression(BaseEstimator):\n",
    "    \"\"\" Regression model which makes the first split according to a specified feature and then splits according to other \n",
    "    algorithms. The model optimizes onset-situation predictions by fitting a two-part model and combining predictions:\n",
    "            1) binary classifier\n",
    "            2) continuous regression\n",
    "    Implementeted as a valid sklearn estimator, so it can be used in pipelines and GridSearch objects.\n",
    "    Args:\n",
    "        ones_name: model to estimate if z variable is one (e.g. \"onset\")\n",
    "        zeros_name: model to estimate if z variable is zeros (e.g. \"continuation\")\n",
    "        ones_params: dict of parameters to pass to \"ones\" sub-model when initialized\n",
    "        zeros_params: dict of parameters to pass to \"zeros\" sub-model when initialized\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ones_name: str = 'RFRegressor',\n",
    "                 zeros_name: str = 'RFRegressor',\n",
    "                 ones_indicator: str = '',\n",
    "                 ones_params: Optional[dict] = None,\n",
    "                 zeros_params: Optional[dict] = None):\n",
    "\n",
    "        self.ones_name = ones_name\n",
    "        self.zeros_name = zeros_name\n",
    "        self.ones_indicator = ones_indicator\n",
    "        self.ones_params = ones_params\n",
    "        self.zeros_params = zeros_params\n",
    "        self.ones_fi = []\n",
    "        self.zeros_fi = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _resolve_estimator(func_name: str):\n",
    "        \"\"\" Lookup table for supported estimators.\n",
    "        This is necessary because sklearn estimator default arguments\n",
    "        must pass equality test, and instantiated sub-estimators are not equal. \"\"\"\n",
    "\n",
    "        funcs = {'linear': LinearRegression(),\n",
    "                 'logistic': LogisticRegression(solver='liblinear'),\n",
    "                 'LGBMRegressor': LGBMRegressor(n_estimators=250),\n",
    "                 'LGBMClassifier': LGBMClassifier(n_estimators=250),\n",
    "                 'RFRegressor': XGBRFRegressor(n_estimators=250,n_jobs=-2),\n",
    "                 'RFClassifier': XGBRFClassifier(n_estimators=250,n_jobs=-2),\n",
    "                 'GBMRegressor': GradientBoostingRegressor(n_estimators=200),\n",
    "                 'GBMClassifier': GradientBoostingClassifier(n_estimators=200),\n",
    "                 'XGBRegressor': XGBRegressor(n_estimators=100,learning_rate=0.05,n_jobs=-2),\n",
    "                 'XGBClassifier': XGBClassifier(n_estimators=100,learning_rate=0.05,n_jobs=-2),\n",
    "                 'HGBRegressor': HistGradientBoostingRegressor(max_iter=200),\n",
    "                 'HGBClassifier': HistGradientBoostingClassifier(max_iter=200),\n",
    "                }\n",
    "\n",
    "        return funcs[func_name]\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[np.ndarray, pd.DataFrame],\n",
    "            y: Union[np.ndarray, pd.Series],\n",
    "            z: Union[np.ndarray, pd.Series]):\n",
    "        X, y = check_X_y(X, y, dtype=None,\n",
    "                         accept_sparse=False,\n",
    "                         accept_large_sparse=False,\n",
    "                         force_all_finite='allow-nan')\n",
    "        z = X[ones_indicator]\n",
    "\n",
    "        if X.shape[1] < 2:\n",
    "            raise ValueError('Cannot fit model when n_features = 1')\n",
    "\n",
    "        self.ones_ = self._resolve_estimator(self.ones_name)\n",
    "        if self.ones_params:\n",
    "            self.ones_.set_params(**self.ones_params)\n",
    "        self.ones_.fit(X[z==1], y[z==1])\n",
    "        self.ones_fi = self.ones_.feature_importances_\n",
    "\n",
    "        self.zeros_ = self._resolve_estimator(self.zeros_name)\n",
    "        if self.zeros_params:\n",
    "            self.zeros_.set_params(**self.zeros_params)\n",
    "        self.zeros_.fit(X[z==0], y[z==0])\n",
    "        self.zeros_fi = self.zeros_.feature_importances_\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "#    def predict_expected_value(self, X: Union[np.ndarray, pd.DataFrame]):\n",
    "        \"\"\" Predict combined response using probabilistic classification outcome \"\"\"\n",
    "        X = check_array(X, accept_sparse=False, accept_large_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "#        predict = \n",
    "        return self.clf_.predict_proba(X)[:, 1] * self.reg_.predict(X)\n",
    "\n",
    "def manual_test():\n",
    "    \"\"\" Validate estimator using sklearn's provided utility and ensure it can fit and predict on fake dataset. \"\"\"\n",
    "    check_estimator(HurdleRegression)\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression()\n",
    "    reg = FixedFirstSplitRegression()\n",
    "    reg.fit(X, y)\n",
    "    reg.predict(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc3fa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FixedFirstSplitRegression(ones_name=&#x27;LGBMClassifier&#x27;,\n",
       "                          zeros_name=&#x27;LGBMRegressor&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FixedFirstSplitRegression</label><div class=\"sk-toggleable__content\"><pre>FixedFirstSplitRegression(ones_name=&#x27;LGBMClassifier&#x27;,\n",
       "                          zeros_name=&#x27;LGBMRegressor&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "FixedFirstSplitRegression(ones_name='LGBMClassifier',\n",
       "                          zeros_name='LGBMRegressor')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FixedFirstSplitRegression(ones_name='LGBMClassifier', zeros_name='LGBMRegressor', ones_indicator = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e75122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    conflictlong_ln: A dataset with 63 columns, with data between t = 1 and 852; 213 units.\n",
      " .    vdem_short: A dataset with 63 columns, with data between t = 1 and 852; 213 units.\n",
      " .    joint_broad: A dataset with 108 columns, with data between t = 1 and 852; 213 units.\n",
      " .    topics_003: A dataset with 68 columns, with data between t = 1 and 852; 213 units.\n",
      " .    wdi_short: A dataset with 32 columns, with data between t = 1 and 852; 213 units.\n",
      " .    all_features: A dataset with 186 columns, with data between t = 1 and 852; 213 units.\n",
      " .    baseline003: A dataset with 6 columns, with data between t = 1 and 852; 213 units.\n",
      " .    joint_narrow: A dataset with 39 columns, with data between t = 1 and 852; 213 units.\n",
      " .    conflict_ln: A dataset with 30 columns, with data between t = 1 and 852; 213 units.\n",
      "all_features [9.99840484e-01 1.59318589e-04 1.96990535e-07 2.59914144e-13\n",
      " 5.37470633e-16 5.77311028e-17 4.60799782e-17 1.25960180e-17\n",
      " 9.98533092e-18 3.88488306e-18 5.68618444e-19 1.03848420e-20\n",
      " 1.25981833e-21 1.12590704e-21 9.64861619e-22 2.99707091e-23\n",
      " 1.51820373e-23 1.35812991e-23 1.14090555e-23 7.92910035e-24]\n",
      "[2.86962084e+16 3.62236647e+14 1.27374308e+13 1.46310036e+10\n",
      " 6.65329115e+08 2.18054014e+08 1.94811814e+08 1.01853462e+08\n",
      " 9.06860300e+07 5.65650446e+07 2.16406166e+07 2.92455037e+06\n",
      " 1.01862216e+06 9.62964833e+05 8.91439090e+05 1.57111389e+05\n",
      " 1.11821210e+05 1.05762039e+05 9.69357569e+04 8.08111181e+04]\n",
      "topics [1.00000000e+00 2.40404612e-11 3.28451028e-13 7.23176772e-14\n",
      " 4.03766444e-14 2.55736800e-14 2.23265199e-14 1.64650203e-14\n",
      " 1.57374920e-14 1.30159920e-14]\n",
      "[3.55548124e+10 1.74329060e+05 2.03766931e+04 9.56138102e+03\n",
      " 7.14436283e+03 5.68584484e+03 5.31262190e+03 4.56225469e+03\n",
      " 4.46032138e+03 4.05636500e+03]\n",
      "vdem [9.99997984e-01 2.01631280e-06 2.39517587e-11 5.60249786e-14\n",
      " 8.22208742e-16 2.68942261e-16 1.34288237e-16 5.42275020e-17\n",
      " 4.27413224e-17 3.38483220e-17 1.72177750e-17 1.05019336e-17\n",
      " 8.98259520e-18 7.39613837e-18 6.21392010e-18]\n",
      "[3.55548129e+10 5.04867934e+07 1.74007328e+05 8.41568913e+03\n",
      " 1.01950622e+03 5.83080290e+02 4.12019548e+02 2.61823506e+02\n",
      " 2.32446394e+02 2.06855659e+02 1.47532380e+02 1.15221485e+02\n",
      " 1.06561359e+02 9.66944058e+01 8.86301874e+01]\n",
      "wdi [9.99840484e-01 1.59318589e-04 1.96990535e-07 2.59914133e-13\n",
      " 5.37452004e-16 5.77204273e-17 4.60114365e-17 1.25702694e-17\n",
      " 9.89799023e-18 1.96594117e-18 3.56845778e-23 1.08282091e-23\n",
      " 7.39135051e-25 2.67744795e-25 4.00541848e-26]\n",
      "[2.86962084e+16 3.62236647e+14 1.27374308e+13 1.46310032e+10\n",
      " 6.65317584e+08 2.18033852e+08 1.94666874e+08 1.01749305e+08\n",
      " 9.02885481e+07 4.02387441e+07 1.71434980e+05 9.44359765e+04\n",
      " 2.46729488e+04 1.48497683e+04 5.74358573e+03]\n"
     ]
    }
   ],
   "source": [
    "from FetchData import fetch_cm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_cm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33277e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queryset(name='fatalities003_topics', loa='country_month', themes=['fatalities003'], description='Predicting ln(fatalities), cm level\\n    \\n                           Queryset with baseline and Mueller & Rauh topic model features\\n    \\n                           ', operations=[[RenameOperation(namespace='trf', name='util.rename', arguments=['ged_sb_dep']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='ged2_cm.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ged_sb']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='ged2_cm.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['decay_ged_sb_5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='ged2_cm.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['decay_ged_os_5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='ged2_cm.ged_os_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_1_decay_ged_sb_5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['5']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='ged2_cm.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['wdi_sp_pop_totl']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='wdi_cy.wdi_sp_pop_totl', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic0_religion_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_religion', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic0_religion_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_religion', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic0_religion_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_religion', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic1_religion_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_religion', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic1_politics_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_politics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic1_politics_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_politics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic1_politics_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_politics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic2_politics_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_politics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic2_sanctions_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sanctions', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic2_sanctions_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sanctions', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic2_sanctions_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sanctions', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic2_sanctions_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sanctions', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic3_life_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_life', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic3_life_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_life', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic3_life_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_life', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic3_life_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_life', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic4_energy_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_energy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic4_energy_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_energy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic4_energy_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_energy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic4_energy_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_energy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic5_media_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_media', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic5_media_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_media', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic5_media_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_media', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic5_media_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_media', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic6_economics_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_economics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic6_economics_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_economics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic6_economics_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_economics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic6_economics_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_economics', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic7_health_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_health', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic7_health_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_health', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic7_health_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_health', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic7_health_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_health', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic8_china_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_china', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic8_china_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_china', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic8_china_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_china', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic8_china_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_china', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic9_foreign_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_foreign', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic9_foreign_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_foreign', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic9_foreign_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_foreign', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic9_foreign_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_foreign', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic10_conflict_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic10_conflict_t2']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['2']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic10_conflict_t3']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['3']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic10_conflict_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic10_conflict_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic10_conflict_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_conflict', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic11_diplomacy_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_diplomacy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic11_diplomacy_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_diplomacy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic11_diplomacy_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_diplomacy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic11_diplomacy_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_diplomacy', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic12_power_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_power', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic12_power_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_power', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic12_power_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_power', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic12_power_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_power', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic13_sports_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sports', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic13_sports_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sports', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic13_sports_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sports', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic13_sports_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_sports', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic14_judiciary_t1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_judiciary', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic14_judiciary_t13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['13']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_judiciary', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['topic14_judiciary_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_judiciary', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_topic14_judiciary_t1_stock']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.countrylag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.moving_average', arguments=['12']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='temporal.tlag', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='topic_cm.topic_judiciary', arguments=['values'])]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qslist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925bdb3",
   "metadata": {},
   "source": [
    "# Generating predictions\n",
    "Using the ViEWS3 partitioning/stepshifting syntax. Training models for A: calibration partition and B: test partition, to test out some calibration routines. Most models trained with ln_ged_sb_best as outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6424da7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fatalities003'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4b379f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gleditsch_ward</th>\n",
       "      <th>ged_sb_dep</th>\n",
       "      <th>ged_sb</th>\n",
       "      <th>ged_sb_tlag_1</th>\n",
       "      <th>ged_sb_tlag_2</th>\n",
       "      <th>ged_sb_tlag_3</th>\n",
       "      <th>ged_sb_tlag_4</th>\n",
       "      <th>ged_sb_tlag_5</th>\n",
       "      <th>ged_sb_tlag_6</th>\n",
       "      <th>ged_sb_tsum_24</th>\n",
       "      <th>...</th>\n",
       "      <th>ln_acled_os_tlag_1</th>\n",
       "      <th>ln_acled_os_tlag_2</th>\n",
       "      <th>ln_acled_ns_tlag_1</th>\n",
       "      <th>ln_acled_ns_tlag_2</th>\n",
       "      <th>splag_1_decay_ged_sb_5</th>\n",
       "      <th>splag_1_decay_ged_os_5</th>\n",
       "      <th>splag_1_decay_ged_ns_5</th>\n",
       "      <th>splag_1_decay_ged_sb_100</th>\n",
       "      <th>splag_1_decay_ged_os_100</th>\n",
       "      <th>splag_1_decay_ged_ns_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>990.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gleditsch_ward  ged_sb_dep  ged_sb  ged_sb_tlag_1  \\\n",
       "month_id country_id                                                      \n",
       "1        1                    110.0         0.0     0.0            0.0   \n",
       "         2                    115.0         0.0     0.0            0.0   \n",
       "         3                     52.0         0.0     0.0            0.0   \n",
       "         4                    101.0         0.0     0.0            0.0   \n",
       "         5                    990.0         0.0     0.0            0.0   \n",
       "\n",
       "                     ged_sb_tlag_2  ged_sb_tlag_3  ged_sb_tlag_4  \\\n",
       "month_id country_id                                                \n",
       "1        1                     0.0            0.0            0.0   \n",
       "         2                     0.0            0.0            0.0   \n",
       "         3                     0.0            0.0            0.0   \n",
       "         4                     0.0            0.0            0.0   \n",
       "         5                     0.0            0.0            0.0   \n",
       "\n",
       "                     ged_sb_tlag_5  ged_sb_tlag_6  ged_sb_tsum_24  ...  \\\n",
       "month_id country_id                                                ...   \n",
       "1        1                     0.0            0.0             0.0  ...   \n",
       "         2                     0.0            0.0             0.0  ...   \n",
       "         3                     0.0            0.0             0.0  ...   \n",
       "         4                     0.0            0.0             0.0  ...   \n",
       "         5                     0.0            0.0             0.0  ...   \n",
       "\n",
       "                     ln_acled_os_tlag_1  ln_acled_os_tlag_2  \\\n",
       "month_id country_id                                           \n",
       "1        1                          0.0                 0.0   \n",
       "         2                          0.0                 0.0   \n",
       "         3                          0.0                 0.0   \n",
       "         4                          0.0                 0.0   \n",
       "         5                          0.0                 0.0   \n",
       "\n",
       "                     ln_acled_ns_tlag_1  ln_acled_ns_tlag_2  \\\n",
       "month_id country_id                                           \n",
       "1        1                          0.0                 0.0   \n",
       "         2                          0.0                 0.0   \n",
       "         3                          0.0                 0.0   \n",
       "         4                          0.0                 0.0   \n",
       "         5                          0.0                 0.0   \n",
       "\n",
       "                     splag_1_decay_ged_sb_5  splag_1_decay_ged_os_5  \\\n",
       "month_id country_id                                                   \n",
       "1        1                              0.0                     0.0   \n",
       "         2                              0.0                     0.0   \n",
       "         3                              0.0                     0.0   \n",
       "         4                              0.0                     0.0   \n",
       "         5                              0.0                     0.0   \n",
       "\n",
       "                     splag_1_decay_ged_ns_5  splag_1_decay_ged_sb_100  \\\n",
       "month_id country_id                                                     \n",
       "1        1                              0.0                       0.0   \n",
       "         2                              0.0                       0.0   \n",
       "         3                              0.0                       0.0   \n",
       "         4                              0.0                       0.0   \n",
       "         5                              0.0                       0.0   \n",
       "\n",
       "                     splag_1_decay_ged_os_100  splag_1_decay_ged_ns_100  \n",
       "month_id country_id                                                      \n",
       "1        1                                0.0                       0.0  \n",
       "         2                                0.0                       0.0  \n",
       "         3                                0.0                       0.0  \n",
       "         4                                0.0                       0.0  \n",
       "         5                                0.0                       0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datasets[0]['df'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990574dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ModelMetadata in module views_schema.models:\n",
      "\n",
      "class ModelMetadata(pydantic.main.BaseModel)\n",
      " |  ModelMetadata(*, author: str, queryset_name: str, train_start: int, train_end: int, steps: List[int] = None, training_date: datetime.datetime) -> None\n",
      " |  \n",
      " |  ModelMetadata\n",
      " |  =============\n",
      " |  \n",
      " |  Data used to organize model objects.\n",
      " |  \n",
      " |  parameters:\n",
      " |      author (str): Name of the user that authored the model object.\n",
      " |      queryset_name (str): Name of the queryset used to train the model\n",
      " |      train_start (int): Month identifier for training start date\n",
      " |      train_start (int): Month identifier for training end date\n",
      " |      training_date (datetime.datetime): Timestamp for training date (use datetime.datetime.now())\n",
      " |  \n",
      " |  example:\n",
      " |  \n",
      " |      # Instantiate the class with values\n",
      " |  \n",
      " |      my_metadata = ModelMetadata(\n",
      " |          author = \"my_name\",\n",
      " |          queryset_name = \"my_queryset\",\n",
      " |          train_start = 1,\n",
      " |          train_end = 300,\n",
      " |          steps = [1,2,3],\n",
      " |          training_date = datetime.datetime.now())\n",
      " |  \n",
      " |      # Create metadata with a views_runs.ViewsRun object. This fetches\n",
      " |      # values from the associated StepshiftedModels and DataPartitioner\n",
      " |      # objects.\n",
      " |  \n",
      " |      my_metadata = my_run.create_model_metadata(\n",
      " |              author = \"me\",\n",
      " |              queryset_name = \"my_queryset\",\n",
      " |              training_partition_name = \"A\",\n",
      " |              )\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ModelMetadata\n",
      " |      pydantic.main.BaseModel\n",
      " |      pydantic.utils.Representation\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'author': <class 'str'>, 'queryset_name': <class 's...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'views_schema.models.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = None\n",
      " |  \n",
      " |  __fields__ = {'author': ModelField(name='author', type=str, required=T...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = []\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {}\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (*, author: str, queryset_name: str, ... No...\n",
      " |  \n",
      " |  __validators__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |  \n",
      " |  __getstate__(self) -> 'DictAny'\n",
      " |  \n",
      " |  __init__(__pydantic_self__, **data: Any) -> None\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __repr_args__(self) -> 'ReprArgs'\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |  \n",
      " |  __setstate__(self, state: 'DictAny') -> None\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, update: 'DictStrAny' = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, by_alias: bool = False, skip_defaults: bool = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |  \n",
      " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny')] = None, by_alias: bool = False, skip_defaults: bool = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |  \n",
      " |  Config = <class 'pydantic.config.BaseConfig'>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> 'unicode'\n",
      " |  \n",
      " |  __repr_name__(self) -> 'unicode'\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      " |  \n",
      " |  __str__(self) -> 'unicode'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from views_runs import ModelMetadata \n",
    "help(ModelMetadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf49bd2",
   "metadata": {},
   "source": [
    "## Checking missingness and infinity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe61e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conflictlong_ln\n",
      "vdem_short\n",
      "joint_broad\n",
      "topics_003\n",
      "wdi_short\n",
      "all_features\n",
      "baseline003\n",
      "joint_narrow\n",
      "conflict_ln\n",
      "pca_all\n",
      "pca_topics\n",
      "pca_vdem\n",
      "pca_wdi\n"
     ]
    }
   ],
   "source": [
    "N=51\n",
    "for i in range(len(Datasets)):\n",
    "    df = Datasets[i]['df']\n",
    "    print(Datasets[i]['Name'])\n",
    "    for col in df.iloc[: , :N].columns:\n",
    "        if df[col].isnull().sum() > 0 or np.isinf(df).values.sum() > 0:\n",
    "            print(col,len(df[col]), 'missing:', df[col].isnull().sum(), 'infinity:', np.isinf(df).values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761eb9c",
   "metadata": {},
   "source": [
    "# Specify models in ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "425514d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities003_nl_baseline_rf baseline003\n",
      "1 fatalities003_nl_conflicthistory_rf conflict_ln\n",
      "2 fatalities003_nl_conflicthistory_hurdle_lgb conflict_ln\n",
      "3 fatalities003_nl_conflicthistory_long_xgb conflictlong_ln\n",
      "4 fatalities003_nl_vdem_hurdle_xgb vdem_short\n",
      "5 fatalities003_nl_wdi_rf wdi_short\n",
      "6 fatalities003_nl_topics_rf topics_003\n",
      "7 fatalities003_nl_topics_xgb topics_003\n",
      "8 fatalities003_nl_topics_hurdle_lgb topics_003\n",
      "9 fatalities003_nl_joint_broad_rf joint_broad\n",
      "10 fatalities003_nl_joint_broad_hurdle_rf joint_broad\n",
      "11 fatalities003_joint_narrow_xgb joint_narrow\n",
      "12 fatalities003_nl_joint_narrow_hurdle_xgb joint_narrow\n",
      "13 fatalities003_nl_joint_narrow_hurdle_lgb joint_narrow\n",
      "14 fatalities003_nl_all_pca3_xgb all_features\n"
     ]
    }
   ],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels('cm')\n",
    "    \n",
    "for imodel,model in enumerate(ModelList):\n",
    "    print(imodel, model['modelname'], model['data_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b1b6322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelname': 'fatalities003_nl_baseline_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'baseline003',\n",
       "  'queryset': 'fatalities003_baseline',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': 'Baseline model with a few conflict history features as well as log population, random forests regression model.',\n",
       "  'long_description': 'A very simple model with only five data columns (each column representing one feature): The number of fatalities in the same country at $t-1$, three decay functions of time since there was at least five fatalities in a single month, for each of the UCDP conflict types -- state-based, one-sided, or non-state conflict -- and log population size (Hegre2020RP,Pettersson2021JPR).The features in the baseline are included in all the models described below. This ensures that all models in the ensemble provides at least moderately good predictions, while guaranteeing diversity in feature sets and modelling approaches.',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_baseline_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_baseline_rf_test'},\n",
       " {'modelname': 'fatalities003_nl_conflicthistory_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'conflict_ln',\n",
       "  'queryset': 'fatalities003_conflict_history',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': 'A collection of variables that together map the conflict history of a country, random forests regression model.',\n",
       "  'long_description': 'A collection of variables that together map the conflict history of a country. The features include lagged dependent variables for each conflict type as coded by the UCDP (state-based, one-sided, or non-state) for up to each of the preceding six months, decay functions of time since conflict caused 5, 100, and 500 deaths in a month, for each type of violence, whether ACLED (https://doi.org/10.1177/0022343310378914 recorded similar violence, and whether there was recent violence in any neighboring countries.',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_conflicthistory_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_conflicthistory_rf_test'},\n",
       " {'modelname': 'fatalities003_nl_conflicthistory_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'conflict_ln',\n",
       "  'queryset': 'fatalities003_conflict_history',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_conflicthistory_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_conflicthistory_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities003_nl_conflicthistory_long_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'conflictlong_ln',\n",
       "  'queryset': 'fatalities003_conflict_history_long',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_conflicthistory_long_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_conflicthistory_long_xgb_test'},\n",
       " {'modelname': 'fatalities003_nl_vdem_hurdle_xgb',\n",
       "  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'vdem_short',\n",
       "  'queryset': 'fatalities003_vdem_short',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_vdem_hurdle_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_vdem_hurdle_xgb_test'},\n",
       " {'modelname': 'fatalities003_nl_wdi_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=300, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'wdi_short',\n",
       "  'queryset': 'fatalities003_wdi_short',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_wdi_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_wdi_rf_test'},\n",
       " {'modelname': 'fatalities003_nl_topics_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'topics_003',\n",
       "  'queryset': 'fatalities003_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_topics_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_topics_rf_test'},\n",
       " {'modelname': 'fatalities003_nl_topics_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=80, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'topics_003',\n",
       "  'queryset': 'fatalities003_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_topics_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_topics_xgb_test'},\n",
       " {'modelname': 'fatalities003_nl_topics_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'topics_003',\n",
       "  'queryset': 'fatalities003_topics',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_topics_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_topics_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities003_nl_joint_broad_rf',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'joint_broad',\n",
       "  'queryset': 'fatalities003_joint_broad',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_joint_broad_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_joint_broad_rf_test'},\n",
       " {'modelname': 'fatalities003_nl_joint_broad_hurdle_rf',\n",
       "  'algorithm': HurdleRegression(clf_name='RFClassifier', reg_name='RFRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'joint_broad',\n",
       "  'queryset': 'fatalities003_joint_broad',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_joint_broad_hurdle_rf_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_joint_broad_hurdle_rf_test'},\n",
       " {'modelname': 'fatalities003_joint_narrow_xgb',\n",
       "  'algorithm': XGBRFRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                 colsample_bylevel=None, colsample_bytree=None,\n",
       "                 early_stopping_rounds=None, enable_categorical=False,\n",
       "                 eval_metric=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                 importance_type=None, interaction_constraints=None, max_bin=None,\n",
       "                 max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                 max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                 monotone_constraints=None, n_estimators=250, n_jobs=12,\n",
       "                 num_parallel_tree=None, objective='reg:squarederror',\n",
       "                 predictor=None, random_state=None, reg_alpha=None,\n",
       "                 sampling_method=None, scale_pos_weight=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities003_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_joint_narrow_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_joint_narrow_xgb_test'},\n",
       " {'modelname': 'fatalities003_nl_joint_narrow_hurdle_xgb',\n",
       "  'algorithm': HurdleRegression(clf_name='XGBClassifier', reg_name='XGBRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities003_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_joint_narrow_hurdle_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_joint_narrow_hurdle_xgb_test'},\n",
       " {'modelname': 'fatalities003_nl_joint_narrow_hurdle_lgb',\n",
       "  'algorithm': HurdleRegression(clf_name='LGBMClassifier', reg_name='LGBMRegressor'),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'joint_narrow',\n",
       "  'queryset': 'fatalities003_joint_narrow',\n",
       "  'preprocessing': 'float_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_joint_narrow_hurdle_lgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_joint_narrow_hurdle_lgb_test'},\n",
       " {'modelname': 'fatalities003_nl_all_pca3_xgb',\n",
       "  'algorithm': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, gamma=None,\n",
       "               gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=12,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None,\n",
       "               reg_alpha=None, reg_lambda=None, ...),\n",
       "  'depvar': 'ged_sb_dep',\n",
       "  'data_train': 'all_features',\n",
       "  'queryset': 'fatalities003_all_features',\n",
       "  'preprocessing': 'pca_it',\n",
       "  'level': 'cm',\n",
       "  'description': '',\n",
       "  'long_description': '',\n",
       "  'predstore_calib': 'cm_fatalities003_nl_all_pca3_xgb_calib',\n",
       "  'predstore_test': 'cm_fatalities003_nl_all_pca3_xgb_test'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "613b4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities003_nl_baseline_rf baseline003\n"
     ]
    }
   ],
   "source": [
    "outcome = 'sb'\n",
    "EnsembleMetaData_df = document_ensemble(ModelList,outcome)\n",
    "if username == 'havardhegre1':\n",
    "    filename = overleafpath + f'Tables/Evaluation/Ensemble_{outcome}.md'\n",
    "    EnsembleMetaData_df.to_markdown(index=False, buf=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c58f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities003_nl_baseline_rf\n",
      "Calibration partition 2023-05-27 17:14:22.053192\n",
      " * == Performing a run: \"fatalities003_nl_baseline_rf_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_baseline_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:15:37.589809\n",
      "pr_56_cm_fatalities003_nl_baseline_rf_calib.parquet\n",
      "cm_fatalities003_nl_baseline_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:15:48.309450\n",
      " * == Performing a run: \"fatalities003_nl_baseline_rf_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_baseline_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:17:09.206490\n",
      "pr_56_cm_fatalities003_nl_baseline_rf_test.parquet\n",
      "cm_fatalities003_nl_baseline_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "1 fatalities003_nl_conflicthistory_rf\n",
      "Calibration partition 2023-05-27 17:17:19.901099\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_rf_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:18:56.605774\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_rf_calib.parquet\n",
      "cm_fatalities003_nl_conflicthistory_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:19:07.316329\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_rf_test\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:20:50.890141\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_rf_test.parquet\n",
      "cm_fatalities003_nl_conflicthistory_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "2 fatalities003_nl_conflicthistory_hurdle_lgb\n",
      "Calibration partition 2023-05-27 17:21:01.402417\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_hurdle_lgb_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_hurdle_lgb_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:22:14.744888\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_hurdle_lgb_calib.parquet\n",
      "cm_fatalities003_nl_conflicthistory_hurdle_lgb_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:22:26.769729\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_hurdle_lgb_test\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_hurdle_lgb_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:23:40.670506\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_hurdle_lgb_test.parquet\n",
      "cm_fatalities003_nl_conflicthistory_hurdle_lgb_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "3 fatalities003_nl_conflicthistory_long_xgb\n",
      "Calibration partition 2023-05-27 17:23:52.886369\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_long_xgb_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_long_xgb_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:24:50.345480\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_long_xgb_calib.parquet\n",
      "cm_fatalities003_nl_conflicthistory_long_xgb_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:25:00.791201\n",
      " * == Performing a run: \"fatalities003_nl_conflicthistory_long_xgb_test\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_conflicthistory_long_xgb_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:26:08.151158\n",
      "pr_56_cm_fatalities003_nl_conflicthistory_long_xgb_test.parquet\n",
      "cm_fatalities003_nl_conflicthistory_long_xgb_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "4 fatalities003_nl_vdem_hurdle_xgb\n",
      "Calibration partition 2023-05-27 17:26:19.074987\n",
      " * == Performing a run: \"fatalities003_nl_vdem_hurdle_xgb_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_vdem_hurdle_xgb_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:27:37.671246\n",
      "pr_56_cm_fatalities003_nl_vdem_hurdle_xgb_calib.parquet\n",
      "cm_fatalities003_nl_vdem_hurdle_xgb_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:27:48.192460\n",
      " * == Performing a run: \"fatalities003_nl_vdem_hurdle_xgb_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_vdem_hurdle_xgb_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:29:20.460805\n",
      "pr_56_cm_fatalities003_nl_vdem_hurdle_xgb_test.parquet\n",
      "cm_fatalities003_nl_vdem_hurdle_xgb_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "5 fatalities003_nl_wdi_rf\n",
      "Calibration partition 2023-05-27 17:29:31.102618\n",
      " * == Performing a run: \"fatalities003_nl_wdi_rf_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_wdi_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:31:21.166739\n",
      "pr_56_cm_fatalities003_nl_wdi_rf_calib.parquet\n",
      "cm_fatalities003_nl_wdi_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:31:38.182559\n",
      " * == Performing a run: \"fatalities003_nl_wdi_rf_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_wdi_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:33:43.245620\n",
      "pr_56_cm_fatalities003_nl_wdi_rf_test.parquet\n",
      "cm_fatalities003_nl_wdi_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "6 fatalities003_nl_topics_rf\n",
      "Calibration partition 2023-05-27 17:33:54.306436\n",
      " * == Performing a run: \"fatalities003_nl_topics_rf_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:36:01.036888\n",
      "pr_56_cm_fatalities003_nl_topics_rf_calib.parquet\n",
      "cm_fatalities003_nl_topics_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:36:11.795652\n",
      " * == Performing a run: \"fatalities003_nl_topics_rf_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:38:52.314154\n",
      "pr_56_cm_fatalities003_nl_topics_rf_test.parquet\n",
      "cm_fatalities003_nl_topics_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "7 fatalities003_nl_topics_xgb\n",
      "Calibration partition 2023-05-27 17:39:03.143536\n",
      " * == Performing a run: \"fatalities003_nl_topics_xgb_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_xgb_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:39:45.980779\n",
      "pr_56_cm_fatalities003_nl_topics_xgb_calib.parquet\n",
      "cm_fatalities003_nl_topics_xgb_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:39:56.449200\n",
      " * == Performing a run: \"fatalities003_nl_topics_xgb_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_xgb_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:40:53.490240\n",
      "pr_56_cm_fatalities003_nl_topics_xgb_test.parquet\n",
      "cm_fatalities003_nl_topics_xgb_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "8 fatalities003_nl_topics_hurdle_lgb\n",
      "Calibration partition 2023-05-27 17:41:04.104667\n",
      " * == Performing a run: \"fatalities003_nl_topics_hurdle_lgb_calib\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_hurdle_lgb_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:42:27.217857\n",
      "pr_56_cm_fatalities003_nl_topics_hurdle_lgb_calib.parquet\n",
      "cm_fatalities003_nl_topics_hurdle_lgb_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:42:39.520700\n",
      " * == Performing a run: \"fatalities003_nl_topics_hurdle_lgb_test\" == * \n",
      "Training model(s)...\n",
      "Storing \"fatalities003_nl_topics_hurdle_lgb_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:44:12.666274\n",
      "pr_56_cm_fatalities003_nl_topics_hurdle_lgb_test.parquet\n",
      "cm_fatalities003_nl_topics_hurdle_lgb_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "9 fatalities003_nl_joint_broad_rf\n",
      "Calibration partition 2023-05-27 17:44:25.269489\n",
      " * == Performing a run: \"fatalities003_nl_joint_broad_rf_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_joint_broad_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:47:17.408897\n",
      "pr_56_cm_fatalities003_nl_joint_broad_rf_calib.parquet\n",
      "cm_fatalities003_nl_joint_broad_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:47:28.250544\n",
      " * == Performing a run: \"fatalities003_nl_joint_broad_rf_test\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_joint_broad_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:50:57.802263\n",
      "pr_56_cm_fatalities003_nl_joint_broad_rf_test.parquet\n",
      "cm_fatalities003_nl_joint_broad_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "10 fatalities003_nl_joint_broad_hurdle_rf\n",
      "Calibration partition 2023-05-27 17:51:08.746804\n",
      " * == Performing a run: \"fatalities003_nl_joint_broad_hurdle_rf_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_joint_broad_hurdle_rf_calib\"\n",
      "Trying to retrieve predictions 2023-05-27 17:54:58.474504\n",
      "pr_56_cm_fatalities003_nl_joint_broad_hurdle_rf_calib.parquet\n",
      "cm_fatalities003_nl_joint_broad_hurdle_rf_calib , run Fatalities003 does not exist, predicting\n",
      "Test partition 2023-05-27 17:55:09.517463\n",
      " * == Performing a run: \"fatalities003_nl_joint_broad_hurdle_rf_test\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reordering feature dimension. Save memory by setting the outcome feature as the first column in your dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing \"fatalities003_nl_joint_broad_hurdle_rf_test\"\n",
      "Trying to retrieve predictions 2023-05-27 17:59:57.078598\n",
      "pr_56_cm_fatalities003_nl_joint_broad_hurdle_rf_test.parquet\n",
      "cm_fatalities003_nl_joint_broad_hurdle_rf_test , run Fatalities003 does not exist, predicting\n",
      "**************************************************************\n",
      "11 fatalities003_joint_narrow_xgb\n",
      "Calibration partition 2023-05-27 18:00:08.442041\n",
      " * == Performing a run: \"fatalities003_joint_narrow_xgb_calib\" == * \n",
      "Model object named \"fatalities003_joint_narrow_xgb_calib\" with equivalent metadata already exists.\n",
      "Fetching \"fatalities003_joint_narrow_xgb_calib\" from storage\n",
      "Trying to retrieve predictions 2023-05-27 18:00:10.161423\n",
      "pr_56_cm_fatalities003_joint_narrow_xgb_calib.parquet\n",
      "Test partition 2023-05-27 18:00:13.693742\n",
      " * == Performing a run: \"fatalities003_joint_narrow_xgb_test\" == * \n",
      "Model object named \"fatalities003_joint_narrow_xgb_test\" with equivalent metadata already exists.\n",
      "Fetching \"fatalities003_joint_narrow_xgb_test\" from storage\n",
      "Trying to retrieve predictions 2023-05-27 18:00:15.488458\n",
      "pr_56_cm_fatalities003_joint_narrow_xgb_test.parquet\n",
      "**************************************************************\n",
      "12 fatalities003_nl_joint_narrow_hurdle_xgb\n",
      "Calibration partition 2023-05-27 18:00:19.376947\n",
      " * == Performing a run: \"fatalities003_nl_joint_narrow_hurdle_xgb_calib\" == * \n",
      "Training model(s)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature ged_sb_dep is not a feature in array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/stepshift.py:60\u001b[0m, in \u001b[0;36mset_feature_as_first\u001b[0;34m(x, array)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalibration partition\u001b[39m\u001b[38;5;124m'\u001b[39m, ct)\n\u001b[1;32m     22\u001b[0m     model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgorithm_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunResult_calib\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mRunResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain_or_retrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretrain\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforce_retrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodelstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartitioner\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDataPartitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcalib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcalib_partitioner_dict\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstepshifted_models\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mStepshiftedModels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgorithm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdepvar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRetrieveFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mqueryset_name\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqueryset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartition_name\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcalib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimespan_name\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstorage_name\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodelname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_calib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mauthor_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     ct \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/run_result.py:154\u001b[0m, in \u001b[0;36mRunResult.retrain_or_retrieve\u001b[0;34m(cls, store, partitioner, stepshifted_models, dataset, queryset_name, partition_name, storage_name, author_name, timespan_name, retrain)\u001b[0m\n\u001b[1;32m    152\u001b[0m result\u001b[38;5;241m.\u001b[39mretrained \u001b[38;5;241m=\u001b[39m exists\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model(s)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimespan_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstorage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m store\u001b[38;5;241m.\u001b[39mstore(storage_name, result\u001b[38;5;241m.\u001b[39mrun, result\u001b[38;5;241m.\u001b[39mmetadata, overwrite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/run_result.py:172\u001b[0m, in \u001b[0;36mRunResult._fit\u001b[0;34m(self, partition_name, timespan_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, partition_name, timespan_name):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    _fit\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    ====\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimespan_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/validation.py:23\u001b[0m, in \u001b[0;36mviews_validate.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     dataframe_is_right_format(args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/views_runs/run.py:51\u001b[0m, in \u001b[0;36mViewsRun.fit\u001b[0;34m(self, partition_name, timespan_name, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@validation\u001b[39m\u001b[38;5;241m.\u001b[39mviews_validate\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, partition_name: \u001b[38;5;28mstr\u001b[39m, timespan_name: \u001b[38;5;28mstr\u001b[39m, data: pd\u001b[38;5;241m.\u001b[39mDataFrame)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    fit\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    ===\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    the DataPartitioner.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shifted_partitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimespan_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/views.py:80\u001b[0m, in \u001b[0;36mStepshiftedModels.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_independent_variables \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outcome]\n\u001b[1;32m     79\u001b[0m cube \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cast_views_to_tuf(data)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, dep, indep \u001b[38;5;129;01min\u001b[39;00m stepshift\u001b[38;5;241m.\u001b[39mstepshifted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outcome, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps, cube):\n\u001b[1;32m     81\u001b[0m     dep,indep \u001b[38;5;241m=\u001b[39m [cast\u001b[38;5;241m.\u001b[39mstack_time_unit_feature_cube(xa)\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m xa \u001b[38;5;129;01min\u001b[39;00m (dep,indep)]\n\u001b[1;32m     82\u001b[0m     dep \u001b[38;5;241m=\u001b[39m dep\u001b[38;5;241m.\u001b[39mreshape(dep\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/stepshift.py:95\u001b[0m, in \u001b[0;36mstepshifted\u001b[0;34m(outcome, steps, array)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstepshifted\u001b[39m(\n\u001b[1;32m     76\u001b[0m         outcome: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     77\u001b[0m         steps: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     78\u001b[0m         array: xarray\u001b[38;5;241m.\u001b[39mDataArray\n\u001b[1;32m     79\u001b[0m         )\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Tuple[\u001b[38;5;28mint\u001b[39m, xarray\u001b[38;5;241m.\u001b[39mDataArray, xarray\u001b[38;5;241m.\u001b[39mDataArray], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    stepshifted\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    ===========\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    time-shift step without copying.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mset_feature_as_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     outcomes \u001b[38;5;241m=\u001b[39m array[:,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     97\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m array[:,:,\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/mambaforge/envs/viewser/lib/python3.9/site-packages/stepshift/stepshift.py:62\u001b[0m, in \u001b[0;36mset_feature_as_first\u001b[0;34m(x, array)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a feature in array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m wanted_order \u001b[38;5;241m=\u001b[39m [x] \u001b[38;5;241m+\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m x]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wanted_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m(array\u001b[38;5;241m.\u001b[39mcoords[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdata):\n",
      "\u001b[0;31mValueError\u001b[0m: Feature ged_sb_dep is not a feature in array"
     ]
    }
   ],
   "source": [
    "# Loop that checks whether the model exists, retrains if not, \n",
    "# and stores the predictions if they have not been stored before for this run.\n",
    "# To do: set the data_preprocessing to the function in the model dictionary\n",
    "\n",
    "level = 'cm'\n",
    "includeFuture = False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    if model['algorithm'] != 'Rscript':\n",
    "        force_retrain = False\n",
    "        modelstore = storage.Storage()\n",
    "        ct = datetime.now()\n",
    "        print(i, model['modelname'])\n",
    "        print('Calibration partition', ct)\n",
    "        model['Algorithm_text'] = str(model['algorithm'])\n",
    "        model['RunResult_calib'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"calib\":calib_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"calib\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_calib',\n",
    "                author_name        = \"HH\",\n",
    "        )\n",
    "\n",
    "    #    model['predstore_calib'] = level +  '_' + model['modelname'] + '_calib'\n",
    "        ct = datetime.now()\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "        try:\n",
    "            predictions_calib = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_calib'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_calib'], ', run',  run_id, 'does not exist, predicting')\n",
    "            predictions_calib = model['RunResult_calib'].run.predict(\"calib\",\"predict\", model['RunResult_calib'].data)\n",
    "            predictions_calib.forecasts.set_run(run_id)\n",
    "            predictions_calib.forecasts.to_store(name=model['predstore_calib'])\n",
    "\n",
    "        ct = datetime.now()\n",
    "        print('Test partition', ct)\n",
    "        modelstore = storage.Storage()\n",
    "        model['RunResult_test'] = RunResult.retrain_or_retrieve(\n",
    "                retrain            = force_retrain,\n",
    "                store              = modelstore,\n",
    "                partitioner        = DataPartitioner({\"test\":test_partitioner_dict}),\n",
    "                stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                queryset_name      = model['queryset'],\n",
    "                partition_name     = \"test\",\n",
    "                timespan_name      = \"train\",\n",
    "                storage_name       = model['modelname'] + '_test',\n",
    "                author_name        = \"HH\",\n",
    "        )\n",
    "        ct = datetime.now()\n",
    "        print('Trying to retrieve predictions', ct)\n",
    "    #    model['predstore_test'] = level +  '_' + model['modelname'] + '_test'\n",
    "        try:\n",
    "            predictions_test = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_test'])\n",
    "        except KeyError:\n",
    "            print(model['predstore_test'], ', run', run_id, 'does not exist, predicting')\n",
    "            predictions_test = model['RunResult_test'].run.predict(\"test\",\"predict\",model['RunResult_test'].data)\n",
    "            predictions_test.forecasts.set_run(run_id)\n",
    "            predictions_test.forecasts.to_store(name=model['predstore_test'])\n",
    "        # Predictions for true future\n",
    "        if includeFuture:\n",
    "            ct = datetime.now()\n",
    "            print('Future', ct)\n",
    "            modelstore = storage.Storage()\n",
    "            model['RunResult_future'] = RunResult.retrain_or_retrieve(\n",
    "                    retrain            = force_retrain,\n",
    "                    store              = modelstore,\n",
    "                    partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "                    stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "                    dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "                    queryset_name      = model['queryset'],\n",
    "                    partition_name     = \"test\",\n",
    "                    timespan_name      = \"train\",\n",
    "                    storage_name       = model['modelname'] + '_future',\n",
    "                    author_name        = \"HH\",\n",
    "            )\n",
    "            ct = datetime.now()\n",
    "            print('Trying to retrieve predictions', ct)\n",
    "            model['predstore_future'] = level +  '_' + model['modelname'] + '_f' + str(FutureStart)\n",
    "            try:\n",
    "                predictions_future = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstore_future'])\n",
    "            except KeyError:\n",
    "                print(model['predstore_future'], ', run', run_id, 'does not exist, predicting')\n",
    "                predictions_future = model['RunResult_future'].run.future_point_predict(FutureStart,model['RunResult_future'].data)\n",
    "                predictions_future.forecasts.set_run(run_id)\n",
    "                predictions_future.forecasts.to_store(name=model['predstore_future'])  \n",
    "        print('**************************************************************')\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the future predictions\n",
    "\n",
    "\n",
    "predictions_test.xs(246,level=1).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b52249",
   "metadata": {},
   "source": [
    "## Notes on training time for the various algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are calculated in minutes for the hh20 feature set (with about 40 features), for all 36 steps, calibration (c) and test (t) partitions, also include generating predictions, and are approximate:\n",
    "\n",
    "#nj=12 (number of threads)\n",
    "#scikit random forest:        21:13 (c), 26:20 (t) RandomForestRegressor(n_estimators=200, n_jobs=nj)\n",
    "#XGB random forest:           06:02 (c), 07:51 (t) XGBRFRegressor(n_estimators=300,n_jobs=nj)\n",
    "#scikit gbm:                  13:59 (c), 15:55 (t) GradientBoostingRegressor(), \n",
    "#scikit hurdle random forest: 07:32 (c), 09:49 (t) For both clf and reg: (n_estimators=200, n_jobs=nj)\n",
    "#XGB hurdle xgb:              01:26 (c), 01:32 (t) For both clf and reg:                n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#scikit histgbm:              01:17 (c), 01:20 (t) HistGradientBoostingRegressor(max_iter=200)\n",
    "#XGB xgb:                     01:00 (c), 01:04 (t) XGBRegressor(n_estimators=200,tree_method='hist',n_jobs=nj)\n",
    "#lightgbm gbm:                00:25 (c), --    (t) LGBMRegressor(n_estimators=100,num_threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71483a35",
   "metadata": {},
   "source": [
    "# Various helper functions and tools...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list | grep views-forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7570c6",
   "metadata": {},
   "source": [
    "# Retrieving external forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30211fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve David's Markov models\n",
    "# To do: rewrite the model dictionary to the new, slimmer version.\n",
    "DRList = []\n",
    "\n",
    "\n",
    "model = {\n",
    "    'modelname':   'fat_hh20_Markov_glm',\n",
    "    'algorithm': [],\n",
    "    'depvar': \"ln_ged_sb_dep\",\n",
    "    'data_train':      'hh20',\n",
    "    'queryset': 'hh_20_features',\n",
    "}\n",
    "DRList.append(model)\n",
    "\n",
    "model = {\n",
    "    'modelname':   'fat_hh20_Markov_rf',\n",
    "    'algorithm': [],\n",
    "    'depvar': \"ln_ged_sb_dep\",\n",
    "    'data_train':      'hh20',\n",
    "    'queryset': 'hh_20_features',\n",
    "}\n",
    "\n",
    "DRList.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'/Users/{os.getlogin()}/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "DRList[0]['predictions_file_calib'] = path + 'vmm_glm_hh20_0125_alt_calib.csv'\n",
    "DRList[0]['predictions_file_test'] = path + 'vmm_glm_hh20_0125_alt_test.csv'\n",
    "DRList[0]['predictions_file_future'] = path + 'vmm_glm_hh20_506.csv'\n",
    "\n",
    "DRList[1]['predictions_file_calib'] = path + 'vmm_rf_hh20_0125_alt_calib.csv'\n",
    "DRList[1]['predictions_file_test'] = path + 'vmm_rf_hh20_0125_alt_test.csv'\n",
    "DRList[1]['predictions_file_future'] = path + 'vmm_rf_hh20_505.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7162915",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in ModelList:\n",
    "    print(model['modelname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86478962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Markov models in central storage\n",
    "# Retrieving dependent variable\n",
    "target_calib = pd.DataFrame.forecasts.read_store('cm_fat_conflicthistory_rf_calib', run=run_id)['ln_ged_sb_dep']\n",
    "target_test = pd.DataFrame.forecasts.read_store('cm_fat_conflicthistory_rf_test', run=run_id)['ln_ged_sb_dep']\n",
    "level = 'cm'\n",
    "for model in DRList:\n",
    "    df_calib = pd.read_csv(model['predictions_file_calib'],index_col=['month_id','country_id'])\n",
    "    df_test = pd.read_csv(model['predictions_file_test'],index_col=['month_id','country_id'])\n",
    "    df_future = pd.read_csv(model['predictions_file_future'],index_col=['month_id','country_id'])\n",
    "    df_calib['ln_ged_sb_dep'] = target_calib\n",
    "    df_test['ln_ged_sb_dep'] = target_test\n",
    "    df_future['ln_ged_sb_dep'] = np.nan # Empty dependent variable column for consistency/required by prediction storage function\n",
    "    stored_modelname = level + '_' + model['modelname'] + '_calib'\n",
    "    df_calib.forecasts.set_run(run_id)\n",
    "    df_calib.forecasts.to_store(name=stored_modelname, overwrite=True)\n",
    "    stored_modelname = level + '_' + model['modelname'] + '_test'\n",
    "    df_test.forecasts.set_run(run_id)\n",
    "    df_test.forecasts.to_store(name=stored_modelname, overwrite=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!viewser tables show ged2_pgm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets[1]['df']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
