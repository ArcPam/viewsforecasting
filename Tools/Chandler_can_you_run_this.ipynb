{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4d0c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline queryset pushed forward from the fatalities002, new updated version.\n",
      " Topics has been slightly changed to reflect the new time lag. Note in the future we should be able to tlag by 1 only as for example, by September 7th we should have all data for October. So technically ahead of the ucdp update schedule. For right now, though, we have data through July so given that we are running the model in October I lagged the value by 3 instead of 1. I converted the 1 year lag to 15 months, and then replaced the running average by 3 month lag with stock over 12. Note that the running average is not the exact version as is calculated by Rauh and Muller team but a stand in. Additional variables will be added.\n",
      " Google trends has similarly been lagged to reflect the last available data is August. There might be something wrong with my querysets where the NAs are getting autofilled with 0s when querying. So, I am setting the google_index value by tlag 2. \n",
      " Internet usage is available at country-year level, but through 2020 only. So lag by 2 years or 24 months.\n",
      " I have borrowed the population from features where t12 lag wdi_cy version has been used.\n",
      " Something interesting to note, queryset for google trends does not seem to have NAs inserted, but NAs appear in the datagrip. there does not seem to be an automatic fill zeros so I am not sure what caused the queryset on this data to insert the zeroes. Could not test and figure out more reasons.\n"
     ]
    }
   ],
   "source": [
    "%run cm_queryset_google_topics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d260be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a21f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!viewser tables show internet_usage_our_world_data_cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312c9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    fat_dev_mc_media_baseline; A dataset with 6 columns, with data between t 1 and 852. (213 units)\n",
      " .    fat_dev_mc_media_topics; A dataset with 60 columns, with data between t 1 and 852. (213 units)\n",
      " .    fat_dev_mc_media_google_internet; A dataset with 13 columns, with data between t 1 and 852. (213 units)\n"
     ]
    }
   ],
   "source": [
    "get_cm_querysets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b7edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
