{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a059fec",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a06547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "# sklearn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "RunGeneticAlgo = False\n",
    "level = 'cm'\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "localpath = '/Users/havardhegre/Pickles/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64093b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_modelname_test = level + '_' + 'ensemble_genetic' + '_test'\n",
    "\n",
    "ensemble_test_df = pd.DataFrame.forecasts.read_store(stored_modelname_test, run=run_id)\n",
    "ensemble_test_df.replace([np.inf, -np.inf], 0, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise QS\n",
    "   \n",
    "Fatality_cutoff = 5\n",
    "Time_cutoff = 6\n",
    "\n",
    "queryset = Queryset(\"fatalities_history\", \"country_month\")\n",
    "    # target variable\n",
    "queryset = queryset.with_column(Column(\"ln_ged_sb_dep\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "                 .transform.ops.ln()\n",
    "                 .transform.missing.fill()\n",
    "                )   \n",
    "queryset = queryset.with_column(Column(\"ts_ged_sb_f\" + str(Fatality_cutoff) + \"_t\" + str(Time_cutoff), from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")             \n",
    "             .transform.missing.replace_na()\n",
    "             .transform.bool.gte(Fatality_cutoff)\n",
    "             .transform.temporal.time_since()\n",
    "             .transform.missing.replace_na()\n",
    "             .transform.bool.gte(Time_cutoff)\n",
    "                               )\n",
    "history_df = queryset.publish().fetch()\n",
    "history_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fromdate = test_partitioner_dict['predict'][0]\n",
    "todate = test_partitioner_dict['predict'][1]\n",
    "history_test_df = history_df.loc[fromdate:todate]\n",
    "\n",
    "history_test_df.describe()\n",
    "#ensemble_test_df['ts_ged_sb_5'] = history_test_df['ts_ged_sb_5']\n",
    "#ensemble_test_df['history_class'] = pd.cut(ensemble_test_df['ts_ged_sb_5'], [0, 6, 999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in SurrogateModelSteps:\n",
    "        # Columns to use in surrogate models, with name in predictions dataset (item 0) and in source dataset (item 1)\n",
    "        colnames = [\n",
    "            ['libdem_s_' + str(step),'vdem_v2x_libdem'],\n",
    "            ['depvar_s_' + str(step),'ln_ged_sb_dep'],\n",
    "            ['pop_s_' + str(step),'wdi_sp_pop_totl'],\n",
    "            ['imr_s_' + str(step),'wdi_sp_dyn_imrt_in'],\n",
    "            ['nb_conflict_s_' + str(step),'splag_1_decay_ged_sb_5'],\n",
    "            ['ste10_conflict_s_' + str(step),'ste_theta10'],\n",
    "            ['ste10stock_conflict_s_' + str(step),'ste_theta10_stock']       \n",
    "            \n",
    "        ]\n",
    "        for col in colnames:\n",
    "            Ensemble_df[col[0]] = np.nan\n",
    "            # Reverse stepshifting:\n",
    "            for m in monthrange:\n",
    "                Ensemble_df.loc[m, col[0]] = np.array(data_df[col[1]].loc[m-step])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3470cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in baseline model queryset to do history-contingent evaluation, group cases in two groups\n",
    "\n",
    "# GED, baseline, ln versions of predictors\n",
    "# log variables\n",
    "\n",
    "qs = (Queryset(\"fatalities_history\", \"country_month\")\n",
    "\n",
    "    # target variable\n",
    "    .with_column(Column(\"ln_ged_sb_dep\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "                 .transform.ops.ln()\n",
    "                 .transform.missing.fill()\n",
    "                )                   \n",
    "\n",
    "    # timelag 0 of target variable\n",
    "    .with_column(Column(\"ln_ged_sb\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "                 .transform.ops.ln()\n",
    "                 .transform.missing.fill()\n",
    "                )\n",
    "    # Decay functions\n",
    "    # sb\n",
    "    .with_column(Column(\"ts_ged_sb_5\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "                 .transform.missing.replace_na()\n",
    "                 .transform.bool.gte(5)\n",
    "                 .transform.temporal.time_since()\n",
    "                 .transform.missing.replace_na()\n",
    "                )\n",
    "        .with_theme(\"fatalities\")\n",
    "        .describe(\"\"\"Fatalities conflict history, cm level\n",
    "\n",
    "            For use in evaluation\n",
    "\n",
    "        \"\"\")\n",
    "    )\n",
    "history_df = qs.publish().fetch()\n",
    "\n",
    "print(f\"fatalities_history; \"\n",
    "      f\"A dataset with {len(history_df.columns)} columns, with \"\n",
    "      f\"data between t {min(history_df.index.get_level_values(0))} \"\n",
    "      f\"and {max(history_df.index.get_level_values(0))}. \"\n",
    "      f\"({len(np.unique(history_df.index.get_level_values(1)))} units)\"\n",
    "     )\n",
    "fromdate = test_partitioner_dict['predict'][0]\n",
    "todate = test_partitioner_dict['predict'][1]\n",
    "history_test_df = history_df.loc[fromdate:todate]\n",
    "\n",
    "history_test_df.describe()\n",
    "ensemble_test_df['ts_ged_sb_5'] = history_test_df['ts_ged_sb_5']\n",
    "ensemble_test_df['history_class'] = pd.cut(ensemble_test_df['ts_ged_sb_5'], [0, 6, 999])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensemble_test_df['history_class'].value_counts())\n",
    "grouped = ensemble_test_df.groupby('history_class')\n",
    "percentiles = (0.25,0.5,0.75,0.90,0.95,0.98,0.99,0.995)\n",
    "for name, group in grouped:\n",
    "    print(name)\n",
    "    print(group['ln_ged_sb_dep'].describe(percentiles = percentiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df[['decay_ged_sb_5','history_class']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_results = [] # list to hold evaluation results\n",
    "\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    stepcols.append('step_pred_' + str(step))\n",
    "    \n",
    "for col in stepcols[1:]:\n",
    "    mse_test = mean_squared_error(ensemble_test_df[col], ensemble_test_df['ln_ged_sb_dep'])\n",
    "    print(col, mse_test)\n",
    "    Results = {\n",
    "        'MSE':  mse_test,\n",
    "        'RMSE': np.sqrt(mse_test)\n",
    "    }\n",
    "    Evaluation_results.append(Results)\n",
    "\n",
    "Evaluation_results_df = pd.DataFrame(Evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model['mse_test'].append(mse_test)\n",
    "    test_all_line.append(mse_test)\n",
    "\n",
    "    mse_zeros = mean_squared_error(df_test[col].loc[df_test['ln_ged_sb_dep'] == 0], df_test['ln_ged_sb_dep'].loc[df_test['ln_ged_sb_dep'] == 0])\n",
    "    model['mse_test_zeros'].append(mse_zeros)\n",
    "    test_zeros_line.append(mse_zeros)\n",
    "\n",
    "    mse_nonzeros = mean_squared_error(df_test[col].loc[df_test['ln_ged_sb_dep'] > 0], df_test['ln_ged_sb_dep'].loc[df_test['ln_ged_sb_dep'] > 0])\n",
    "    model['mse_test_nonzeros'].append(mse_nonzeros)\n",
    "    test_nonzeros_line.append(mse_nonzeros)\n",
    "\n",
    "    mse_test_exp = mean_squared_error(df_test_exp[col], target['y_test'])\n",
    "    model['mse_test_exp'].append(mse_test_exp)\n",
    "    test_exp_all_line.append(mse_test_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
