{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b8652",
   "metadata": {},
   "source": [
    "# ViEWS 3 ensembles: future predictions\n",
    "\n",
    "ViEWS monthly updates, cm level Fatalities002 version\n",
    "\n",
    "This notebook produces future predictions for a set of models defined in the list of dictionaries ModelList, produced by the notebook pgm_constituentmodels in this repository.\n",
    "\n",
    "The notebook draws on the following .py script files in this repository:\n",
    "\n",
    "Ensembling.py\n",
    "\n",
    "FetchData.py\n",
    "\n",
    "It also requires the list of models included in the ensemble, in the following file:\n",
    "ModelDefinitions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "import views_mapper2\n",
    "from views_mapper2.mapper2 import Mapper2\n",
    "from views_mapper2 import color\n",
    "from views_mapper2.label_writer import vid2date\n",
    "from views_mapper2.dictionary_writer import standard_scale\n",
    "\n",
    "# Mapper\n",
    "import geopandas as gpd\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "#Parallelization\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Packages from this repository, Tools folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "sys.path.append('../SystemUpdates')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Predicting fatalities scripts\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated, fetch_df_pg_id_c_id, calibrate_pg_with_c\n",
    "\n",
    "from FetchData import FetchData, RetrieveFromList, ReturnQsList, index_check\n",
    "from ViewsEstimators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id \n",
    "EndOfHistory = 508\n",
    "prod_id = '2022_04_t01'\n",
    "level = 'pgm'\n",
    "WriteToOverleaf = False\n",
    "get_future = True\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "depvar = \"ln_ged_sb_dep\"\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,408),\"predict\":(409,456)}\n",
    "test_partitioner_dict = {\"train\":(121,456),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,504),\"predict\":(505,516)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "localgitpath = f'/Users/{username}/views3/'\n",
    "notebookpath = os.getcwd()\n",
    "\n",
    "if WriteToOverleaf:\n",
    "    if EndOfHistory==508:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    if EndOfHistory==509:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    \n",
    "    print('Overleaf path set to',overleafpath)\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349154a",
   "metadata": {},
   "source": [
    "# Retrieve models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gitname = 'EnsembleMetaData_pgm_' + dev_id + '.csv'\n",
    "#EnsembleMetaData = pd.read_csv(gitname)\n",
    "#ModelList = EnsembleMetaData.to_dict('records')\n",
    "#i = 0\n",
    "#for model in ModelList:\n",
    "#    print(i, model['modelname'])\n",
    "#    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433cc7b",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, run_id, level, get_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a0bb5-060e-422e-96f3-79022a797649",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qslist = ReturnQsList(level)\n",
    "from FetchData import fetch_pgm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_pgm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae604617-5937-4f84-8b83-8a4f7321dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8651ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "#    print(model['predictions_calib_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bffe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_const_models=False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "RewritePredictions = False # Set this to True to rewrite predictions even if they exist\n",
    "\n",
    "def RetrainAndPredict(modelname):\n",
    "    force_retrain = False\n",
    "    modelstore = storage.Storage()\n",
    "    # Predictions for true future\n",
    "    ct = datetime.now()\n",
    "    print('Future', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_future']  = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_future',\n",
    "            author_name        = \"JED\",\n",
    "    )       \n",
    "    predictions_future = model['RunResult_future'].run.future_point_predict(EndOfHistory,model['RunResult_future'].data)\n",
    "    return predictions_future\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "print('Computing predictions, production run ' + prod_id + ', development run ' + run_id)\n",
    "for model in ModelList:\n",
    "\n",
    "    # Loop that checks whether (1) this a model trained outside the main system, \n",
    "    # (2) retrieves the prediction if it exists in prediction storage,\n",
    "    # (3) if not checks whether the trained model exists, retrains if not, \n",
    "    # Then calibrates the predictions and stores them if they have not been stored before for this run.\n",
    "    # To do: set the data_preprocessing to the function in the model dictionary\n",
    "    \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        print(model['predstorename_ncal'])\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "        \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "    \n",
    "#    print('before store',model['future_df_noncalibrated'].index.names)\n",
    "        \n",
    "    model['future_df_noncalibrated'].forecasts.set_run(run_id)\n",
    "    model['future_df_noncalibrated'].forecasts.to_store(name=model['predstorename_ncal'], overwrite=True)   \n",
    "    \n",
    "#    print('after store',model['future_df_noncalibrated'].index.names)\n",
    "    \n",
    "    if calibrate_const_models:\n",
    "        print('Calibrating')\n",
    "        model['future_df_calibrated'] = model['future_df_noncalibrated'].copy()\n",
    "            \n",
    "        model['future_df_calibrated']['step_combined']=cal_pg_c(model['future_df_calibrated'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "        # Storing calibrated\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "            \n",
    "    i = i + 1\n",
    "\n",
    "print('All done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e78a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList = [] # Separate list of dictionaries for ensembles!\n",
    "\n",
    "Ensemble = {\n",
    "    'modelname':            'ensemble_cm_calib',\n",
    "    'algorithm':            [],\n",
    "    'depvar':               depvar,\n",
    "    'data_train':           [],\n",
    "    'Algorithm_text':       '',\n",
    "    'calibration_gams':     [],\n",
    "    'future_df_calibrated': [],\n",
    "}\n",
    "EnsembleList.append(Ensemble)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42948b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ensemble=ViewsMetadata().with_name('cm_genetic_ensemble_f'+str(EndOfHistory)).fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_run_id=int(cm_ensemble['runs_id'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_predictions_calib = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_calib')\n",
    "cm_predictions_test = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_test')\n",
    "cm_predictions_future = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_genetic_ensemble_f'+str(EndOfHistory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepcols=['step_pred_' + str(step) for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(ModelList)\n",
    "\n",
    "targetcalib=ModelList[0]['predictions_calib_df'][depvar]\n",
    "targettest=ModelList[0]['predictions_test_df'][depvar]\n",
    "\n",
    "valscalib=ModelList[0]['predictions_calib_df'][stepcols].values.copy()\n",
    "valstest=ModelList[0]['predictions_test_df'][stepcols].values.copy()\n",
    "valsfuture=ModelList[0]['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "trimmed_calib=ModelList[0]['predictions_calib_df'][stepcols].copy()\n",
    "index_calib=trimmed_calib.index\n",
    "columns_calib=trimmed_calib.columns\n",
    "\n",
    "trimmed_test=ModelList[0]['predictions_test_df'][stepcols].copy()\n",
    "index_test=trimmed_test.index\n",
    "columns_test=trimmed_test.columns\n",
    "\n",
    "trimmed_future=ModelList[0]['future_df_noncalibrated'].copy()\n",
    "index_future=trimmed_future.index\n",
    "columns_future=trimmed_future.columns\n",
    "\n",
    "for model in ModelList[1:]:\n",
    "    print('adding',model['modelname'])\n",
    "\n",
    "    valscalib+=model['predictions_calib_df'][stepcols].values.copy()\n",
    "    valstest+=model['predictions_test_df'][stepcols].values.copy()\n",
    "    valsfuture+=model['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "    valscalib/=n_models\n",
    "    valstest/=n_models\n",
    "    valsfuture/=n_models\n",
    "\n",
    "    Ensemble['predictions_calib_df']=pd.DataFrame(data=valscalib, index=index_calib, columns=columns_calib)\n",
    "    Ensemble['predictions_test_df']=pd.DataFrame(data=valstest, index=index_test, columns=columns_test)\n",
    "    Ensemble['predictions_future_df']=pd.DataFrame(data=valsfuture, index=index_future, columns=columns_future)\n",
    "    \n",
    "df_pg_id_c_id=fetch_df_pg_id_c_id()\n",
    "    \n",
    "for col in stepcols:\n",
    "\n",
    "    thisstep=int(''.join([''+str(f) for f in filter(str.isdigit, col)]))\n",
    "    thismonth = EndOfHistory + thisstep\n",
    "\n",
    "    Ensemble['predictions_calib_df'][col]=calibrate_pg_with_c(Ensemble['predictions_calib_df'],cm_predictions_calib,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "\n",
    "    Ensemble['predictions_test_df'][col]=calibrate_pg_with_c(Ensemble['predictions_test_df'],cm_predictions_test,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "    \n",
    "future_calib=calibrate_pg_with_c(Ensemble['predictions_future_df'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "    \n",
    "Ensemble['predictions_future_df']['step_combined']=future_calib['step_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f99bb-01ba-46a2-a506-5d3ea80104b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'][depvar]=targetcalib\n",
    "Ensemble['predictions_test_df'][depvar]=targettest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + Ensemble['modelname'] + '_calib'\n",
    "Ensemble['predictions_calib_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_calib_df'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + Ensemble['modelname'] + '_test'\n",
    "Ensemble['predictions_test_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_test_df'].forecasts.to_store(name=predstore_test, overwrite = True)\n",
    "predstore_future = level +  '_' + Ensemble['modelname'] + '_f'+str(EndOfHistory)\n",
    "Ensemble['predictions_future_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_future_df'].forecasts.to_store(name=predstore_future, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355ad4d",
   "metadata": {},
   "source": [
    "# Use ensemble predictions for test partition to create categorical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48672578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df=Ensemble['predictions_test_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be8760-152e-4c05-a98a-ddcaa964c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dichotomous version of dependent variable\n",
    "ensemble_test_df['ged_gte_25'] = ensemble_test_df['ln_ged_sb_dep'].apply(lambda x: 1 if x >= np.log1p(25) else 0)\n",
    "# Generate multiclass version for uncertainty estimation\n",
    "def ged_categorical(x):\n",
    "    if x < np.log1p(0.5):\n",
    "        return 0\n",
    "    elif x < np.log1p(10):\n",
    "        return 1\n",
    "    elif x < np.log1p(100):\n",
    "        return 2\n",
    "    elif x < np.log1p(1000):\n",
    "        return 3\n",
    "    else :\n",
    "        return 4\n",
    "\n",
    "ensemble_test_df['ged_multi'] = ensemble_test_df['ln_ged_sb_dep'].apply(ged_categorical)\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ensemble_test_df['ln_ged_sb_dep'],ensemble_test_df['ged_multi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e85509-4aaf-4106-909a-691e4ed34851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in steps:\n",
    "    if ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum() != 0:\n",
    "        print('****WARNING***** - detected',ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum(),'Nan(s) in column step_pred_'+str(step))\n",
    "        print('Replacing with zeros')\n",
    "        ensemble_test_df[f'step_pred_{step}']=ensemble_test_df[f'step_pred_{step}'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d86f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to transform predictions from  fatalities to (1) dichotomous and (2) multiclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dichotomous_classifiers = []\n",
    "multi_classifiers = []\n",
    "for step in steps:\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Dichotomous\n",
    "    y_dich = np.array(ensemble_test_df['ged_gte_25']).reshape(-1, 1)\n",
    "    dich_clf = LogisticRegression(random_state=0).fit(X, y_dich)\n",
    "    dichotomous_classifiers.append(dich_clf)\n",
    "    p_dich = dich_clf.predict_proba(X)\n",
    "    ensemble_test_df['dich_step_{step}_logit'] = p_dich[:,1].ravel()\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    p_multi = multi_clf.predict_proba(X)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList[0]['future_df_dichotomous'] = EnsembleList[0]['predictions_future_df'].copy() # Copy from baseline\n",
    "\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "#    weightcol = 'step_pred_' + str(step)\n",
    "#    weights = np.array(pd.DataFrame(i_weights_df[weightcol]))\n",
    "#    EnsembleList[0]['future_df_calibrated'].loc[month] = ConstituentModels_df_w.loc[month].dot(weights).values\n",
    "    x_d = np.array(EnsembleList[0]['predictions_future_df'].loc[month]).reshape(-1,1)\n",
    "    pred_step = dichotomous_classifiers[step-1].predict_proba(x_d)\n",
    "    EnsembleList[0]['future_df_dichotomous']['step_combined'].loc[month] = pred_step[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstore_future_dich = level +  '_' + EnsembleList[0]['modelname'] + '_dich_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.to_store(name=predstore_future_dich, overwrite = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854ca6b",
   "metadata": {},
   "source": [
    "# Mapping future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pgm geometries\n",
    "gdf_base = gpd.read_parquet('../Tools/geometry/pgm_geometry.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5277a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cm geometries\n",
    "gdf_c = gpd.read_parquet('../Tools/geometry/cm_geometry.parquet')\n",
    "gdf_c = gdf_c.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6faa706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_wanted_index=Datasets[0]['df']\n",
    "\n",
    "index_check(EnsembleList[0],df_with_wanted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a029ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future prediction maps, predictions, rolling\n",
    "#path = Mydropbox + 'Projects/PredictingFatalities/maps/cm_future/'\n",
    "stepstoplot=[3,5,6,8,12,18,24,36]\n",
    "#titles = [vid2date(i) for i in stepstoplot + EndOfHistory]\n",
    "\n",
    "\n",
    "df = Ensemble['predictions_future_df'].copy()\n",
    "gdf2 = gdf_base.copy()\n",
    "df = df.join(gdf2.set_index(\"priogrid_gid\"))\n",
    "gdf3 = gpd.GeoDataFrame(df, geometry=\"geom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Mydropbox + 'Projects/PredictingFatalities/Predictions/pgm/preds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "#        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=0.7,facecolor='None')\n",
    "        \n",
    "#        m.cbar.set_ticks(standard_scale)\n",
    "#        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[29.446846321370213, 50.987309710685814, 1.1561557161401845, 18.29970129951559], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'ETHIOPIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.2,0.7,'SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.35,'S. SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.65,0.5,'SOMALIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.35,0.25,'KENYA',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Ethiopia_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e14c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-2.3019466946294584, 20.374695512438592, 1.103974761908613, 16.794164972712068], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'NIGERIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.4,0.7,'NIGER',fontdict=fontdict,color='black')\n",
    "        figure.text(0.5,0.35,'CAMEROON',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.60,'CHAD',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.4,'C.A.R.',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.60,'B. FASO',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Nigeria_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f266a",
   "metadata": {},
   "source": [
    "# Changes to 3- and 6-month forecasts, and since last actual observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d048ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data for mapping\n",
    "# Predictions now and then\n",
    "predstore_then = level +  '_' + EnsembleList[0]['modelname'] + '_f' + str(EndOfHistory-3)\n",
    "\n",
    "df_now = EnsembleList[0]['predictions_future_df'].copy()\n",
    "\n",
    "df_then=ViewsMetadata().with_name('ensemble_cm_calib_f'+str(EndOfHistory-3)).fetch()\n",
    "\n",
    "try:\n",
    "    df_then = pd.DataFrame.forecasts.read_store(run=run_id, name=predstore_then)\n",
    "except:\n",
    "    print('Trouble reading forecasts issued three months ago')\n",
    "    \n",
    "# Actuals\n",
    "\n",
    "df_lastobserved = Datasets[0]['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log of mean non-logged fatalities, past six months\n",
    "df_observed = df_lastobserved.loc[EndOfHistory]\n",
    "df_observed['ged_sb_0'] = np.expm1(df_observed['ln_ged_sb'])\n",
    "df_observed['ged_sum'] = df_observed['ged_sb_0']\n",
    "for t in [1,2,3,4,5]:\n",
    "    colname = 'ged_sb_' + str(t)\n",
    "    df_observed[colname] = np.expm1(df_lastobserved.loc[EndOfHistory-t]['ln_ged_sb'])\n",
    "    df_observed['ged_sum'] = df_observed['ged_sum'] + df_observed[colname]\n",
    "df_observed['ln_ged_sum'] = np.log1p(df_observed['ged_sum']/6)\n",
    "#df_observed.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepsForward = [\n",
    "{\n",
    "    'Step': 3,\n",
    "    'df_now': df_now.loc[EndOfHistory + 3],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 3]\n",
    "},\n",
    "{\n",
    "    'Step': 6,\n",
    "    'df_now': df_now.loc[EndOfHistory + 6],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 6]\n",
    "},\n",
    "]\n",
    "engine = sa.create_engine(source_db_path)\n",
    "#predictors_df = data_vdem_short.loc[EndOfHistory]\n",
    "#predictors_df_3m = data_vdem_short.loc[EndOfHistory-3]\n",
    "\n",
    "for s in StepsForward:\n",
    "    s['df_now'].rename(columns={'step_combined':'Now'}, inplace=True)\n",
    "    s['df_then'].rename(columns={'step_combined':'Then'}, inplace=True)\n",
    "    s['df'] = pd.concat([s['df_now'],s['df_then'],df_observed['ln_ged_sum']],axis=1)\n",
    "    s['df']['Change_in_prediction'] = s['df']['Now']-s['df']['Then']\n",
    "    s['df']['Change_since_last_observed'] = s['df']['Now']-s['df']['ln_ged_sum']\n",
    "    \n",
    "#    # Surrogate model change\n",
    "#    for sm in SurrogateModelList:\n",
    "#        if sm['Step'] == s['Step']:\n",
    "#            s['sdf'] = predictors_df[sm['Columns']]\n",
    "#            s['sdf'][sm['Predcolname']] = sm['GAM'].predict(predictors_df[sm['Columns']])\n",
    "#            s['sdf_3m'] = predictors_df_3m[sm['Columns']]\n",
    "#            s['sdf_3m'][sm['Predcolname']] = sm['GAM'].predict(predictors_df_3m[sm['Columns']])\n",
    "#            print(sm['Step'],sm['Predcolname'])\n",
    "#            dfcolname = sm['Predcolname'][:-2] + '_ch3m'\n",
    "#            s['df'][dfcolname] = s['sdf'][sm['Predcolname']] - s['sdf_3m'][sm['Predcolname']]\n",
    "    \n",
    "    s['gdf'] = gdf_base\n",
    "    s['gdf'] = s['gdf'].to_crs(4326)\n",
    "\n",
    "    s['gdf_t'] = s['df'].join(s['gdf'].set_index(\"priogrid_gid\"))\n",
    "    s['gdf'] = gpd.GeoDataFrame(s['gdf_t'], geometry=\"geom\")\n",
    "    \n",
    "    \n",
    "StepsForward[0]['gdf'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aeb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickvalues = np.array([-80,-50,-20,0,20,50,100,200,500])\n",
    "print(tickvalues)\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "print(tickvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b060b9d-2487-4c35-bfb1-32cd69107b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= Mydropbox + f'DataReleases/MonthlyUpdates/{run_id}_{prod_id}/Continuous/Ensemble/ChangeMaps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e22c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 3\n",
    "\n",
    "tickvalues=np.array([-300,-30,-3,3,30,300])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "\n",
    "tickvalues=np.sign(tickvalues)*np.log1p(np.abs(tickvalues)+1)\n",
    "#print(tickvalues)\n",
    "tickvalues = np.array([-83,-80,-50,-20,0,20,50,100,200,500])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "ticklabels[0] = \"\"\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "\n",
    "\n",
    "t0s=range(508,509) # From start of month A, to start of (but not including) month B\n",
    "bbox=\"africa_middle_east\"\n",
    "cmap='bwr'#'rainbow'\n",
    "for s in StepsForward:\n",
    "    for column in ['Change_in_prediction','Change_since_last_observed']:\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title=f\"{column}, s= {s['Step']}\",\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=s['gdf'],\n",
    "        map_scale=surrogate_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "        column=column, \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        m.cbar.set_ticks(surrogate_scale)\n",
    "        m.cbar.set_ticklabels(surrogate_scale_labels)\n",
    "\n",
    "        m.save(path+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')\n",
    "#        if WriteToOverleaf:\n",
    "#            plot.save(overleafpath+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a07b5-f89d-4ebe-91e9-ea8a8eaf9bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
