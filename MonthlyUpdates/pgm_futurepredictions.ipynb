{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b8652",
   "metadata": {},
   "source": [
    "# ViEWS 3 ensembles: future predictions\n",
    "\n",
    "ViEWS monthly updates, cm level Fatalities002 version\n",
    "\n",
    "This notebook produces future predictions for a set of models defined in the list of dictionaries ModelList, produced by the notebook pgm_constituentmodels in this repository.\n",
    "\n",
    "The notebook draws on the following .py script files in this repository:\n",
    "\n",
    "Ensembling.py\n",
    "\n",
    "FetchData.py\n",
    "\n",
    "It also requires the list of models included in the ensemble, in the following file:\n",
    "ModelDefinitions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf471b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3c1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "import views_mapper2\n",
    "from views_mapper2.mapper2 import Mapper2\n",
    "from views_mapper2 import color\n",
    "from views_mapper2.label_writer import vid2date\n",
    "from views_mapper2.dictionary_writer import standard_scale\n",
    "\n",
    "# Mapper\n",
    "import geopandas as gpd\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "#Parallelization\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# Packages from this repository, Tools folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Tools')\n",
    "sys.path.append('../Intermediates')\n",
    "sys.path.append('../SystemUpdates')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Predicting fatalities scripts\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated, fetch_df_pg_id_c_id, calibrate_pg_with_c\n",
    "\n",
    "from FetchData import FetchData, RetrieveFromList, ReturnQsList, index_check\n",
    "from ViewsEstimators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ec2d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropbox path set to /Users/jim/Dropbox (ViEWS)/ViEWS/\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = dev_id \n",
    "EndOfHistory = 508\n",
    "prod_id = '2022_04_t01'\n",
    "level = 'pgm'\n",
    "WriteToOverleaf = False\n",
    "get_future = True\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "depvar = \"ln_ged_sb_dep\"\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "localgitpath = f'/Users/{username}/views3/'\n",
    "notebookpath = os.getcwd()\n",
    "\n",
    "if WriteToOverleaf:\n",
    "    if EndOfHistory==508:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    if EndOfHistory==509:\n",
    "        overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS_Presentations_2021/Figures/Forecasts/Apr2022/'\n",
    "    \n",
    "    print('Overleaf path set to',overleafpath)\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349154a",
   "metadata": {},
   "source": [
    "# Retrieve models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9144d8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_pgm_baseline_lgbm baseline\n",
      "1 fatalities002_pgm_conflictlong_lgbm conflictlong\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm conflictlong\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm escwa_drought\n",
      "4 fatalities002_pgm_escwa_drought_lgbm escwa_drought\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm natsoc\n",
      "6 fatalities002_pgm_natsoc_lgbm natsoc\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm broad\n",
      "8 fatalities002_pgm_broad_lgbm broad\n",
      "9 fatalities002_pgm_conflict_history_xgb conflicthist\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle conflicttreelag\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle conflictsptime_dist\n"
     ]
    }
   ],
   "source": [
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gitname = 'EnsembleMetaData_pgm_' + dev_id + '.csv'\n",
    "#EnsembleMetaData = pd.read_csv(gitname)\n",
    "#ModelList = EnsembleMetaData.to_dict('records')\n",
    "#i = 0\n",
    "#for model in ModelList:\n",
    "#    print(i, model['modelname'])\n",
    "#    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433cc7b",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edabbed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fatalities002_pgm_baseline_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_baseline_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_baseline_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_baseline_lgbm_f508.parquet\n",
      "1 fatalities002_pgm_conflictlong_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_lgbm_f508.parquet\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_f508.parquet\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_f508.parquet\n",
      "4 fatalities002_pgm_escwa_drought_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_lgbm_f508.parquet\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_hurdle_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_hurdle_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_hurdle_lgbm_f508.parquet\n",
      "6 fatalities002_pgm_natsoc_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_lgbm_f508.parquet\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_broad_hurdle_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_broad_hurdle_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_broad_hurdle_lgbm_f508.parquet\n",
      "8 fatalities002_pgm_broad_lgbm\n",
      "pr_46_pgm_fatalities002_pgm_broad_lgbm_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_broad_lgbm_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_broad_lgbm_f508.parquet\n",
      "9 fatalities002_pgm_conflict_history_xgb\n",
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_f508.parquet\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle\n",
      "pr_46_pgm_fatalities002_pgm_conflict_treelag_hurdle_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_treelag_hurdle_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_treelag_hurdle_f508.parquet\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle\n",
      "pr_46_pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_calib.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_test.parquet\n",
      "pr_46_pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_f508.parquet\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, run_id, level, get_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653a0bb5-060e-422e-96f3-79022a797649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modelname', 'algorithm', 'depvar', 'queryset', 'data_train', 'level', 'preprocessing', 'description', 'long_description', 'predstore_calib', 'predstore_test', 'predictions_calib_df', 'predictions_test_df', 'predictions_future_df'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelList[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45eb1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .    \n",
      "A dataset with 8 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 19 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 29 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 24 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 23 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 30 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 8 columns, with data between t 1 and 852. (13110 units)\n",
      " .    \n",
      "A dataset with 11 columns, with data between t 1 and 852. (13110 units)\n",
      " .    escwa_drought: A dataset with 29 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    baseline: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conflicttreelag: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conflictlong: A dataset with 19 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conflictsptime_dist: A dataset with 11 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    natsoc: A dataset with 24 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conflicthist: A dataset with 30 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    broad: A dataset with 23 columns, with data between t = 1 and 852; 13110 units.\n"
     ]
    }
   ],
   "source": [
    "qslist = ReturnQsList(level)\n",
    "from FetchData import fetch_pgm_data_from_model_def\n",
    "\n",
    "Datasets=fetch_pgm_data_from_model_def(qslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae604617-5937-4f84-8b83-8a4f7321dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8651ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatalities002_pgm_baseline_lgbm\n",
      "fatalities002_pgm_conflictlong_lgbm\n",
      "fatalities002_pgm_conflictlong_hurdle_lgbm\n",
      "fatalities002_pgm_escwa_drought_hurdle_lgbm\n",
      "fatalities002_pgm_escwa_drought_lgbm\n",
      "fatalities002_pgm_natsoc_hurdle_lgbm\n",
      "fatalities002_pgm_natsoc_lgbm\n",
      "fatalities002_pgm_broad_hurdle_lgbm\n",
      "fatalities002_pgm_broad_lgbm\n",
      "fatalities002_pgm_conflict_history_xgb\n",
      "fatalities002_pgm_conflict_treelag_hurdle\n",
      "fatalities002_pgm_conflict_sptime_dist_hurdle\n"
     ]
    }
   ],
   "source": [
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "#    print(model['predictions_calib_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bffe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions, production run 2022_04_t01, development run Fatalities002\n",
      "0 fatalities002_pgm_baseline_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:01:41.369270\n",
      "pr_46_pgm_fatalities002_pgm_baseline_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_baseline_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "0 fatalities002_pgm_baseline_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:01:44.916496\n",
      "pr_46_pgm_fatalities002_pgm_baseline_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_baseline_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 753, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1004, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 683, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.DatabaseError: could not receive data from server: Operation timed out\n",
      "SSL SYSCALL error: Operation timed out\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fatalities002_pgm_conflictlong_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:18.934191\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflictlong_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "1 fatalities002_pgm_conflictlong_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:22.057394\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflictlong_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:37.343712\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "2 fatalities002_pgm_conflictlong_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:46.623267\n",
      "pr_46_pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflictlong_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:56.689089\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "3 fatalities002_pgm_escwa_drought_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:02:59.488393\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_escwa_drought_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "4 fatalities002_pgm_escwa_drought_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:03:15.122073\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_escwa_drought_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "4 fatalities002_pgm_escwa_drought_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:03:21.222070\n",
      "pr_46_pgm_fatalities002_pgm_escwa_drought_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_escwa_drought_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:03:35.975555\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_natsoc_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "5 fatalities002_pgm_natsoc_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:03:39.279240\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_natsoc_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "6 fatalities002_pgm_natsoc_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:03:58.112270\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_natsoc_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "6 fatalities002_pgm_natsoc_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:08.040921\n",
      "pr_46_pgm_fatalities002_pgm_natsoc_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_natsoc_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:17.517229\n",
      "pr_46_pgm_fatalities002_pgm_broad_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_broad_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "7 fatalities002_pgm_broad_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:20.824986\n",
      "pr_46_pgm_fatalities002_pgm_broad_hurdle_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_broad_hurdle_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "8 fatalities002_pgm_broad_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:30.121170\n",
      "pr_46_pgm_fatalities002_pgm_broad_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_broad_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "8 fatalities002_pgm_broad_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:34.604705\n",
      "pr_46_pgm_fatalities002_pgm_broad_lgbm_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_broad_lgbm_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "9 fatalities002_pgm_conflict_history_xgb\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:44.113383\n",
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_history_xgb_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "9 fatalities002_pgm_conflict_history_xgb\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:04:47.394343\n",
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_history_xgb_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:05:01.507247\n",
      "pr_46_pgm_fatalities002_pgm_conflict_treelag_hurdle_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_treelag_hurdle_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "10 fatalities002_pgm_conflict_treelag_hurdle\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:05:04.334479\n",
      "pr_46_pgm_fatalities002_pgm_conflict_treelag_hurdle_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_treelag_hurdle_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:05:14.727168\n",
      "pr_46_pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "11 fatalities002_pgm_conflict_sptime_dist_hurdle\n",
      "Trying to retrieve non-calibrated predictions 2022-11-09 11:05:17.851190\n",
      "pr_46_pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_f508.parquet\n",
      "Predictions for  pgm_fatalities002_pgm_conflict_sptime_dist_hurdle_f508 , run Fatalities002 exist, retrieving from prediction storage\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "calibrate_const_models=False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "RewritePredictions = False # Set this to True to rewrite predictions even if they exist\n",
    "\n",
    "def RetrainAndPredict(modelname):\n",
    "    force_retrain = False\n",
    "    modelstore = storage.Storage()\n",
    "    # Predictions for true future\n",
    "    ct = datetime.now()\n",
    "    print('Future', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_future']  = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_future',\n",
    "            author_name        = \"JED\",\n",
    "    )       \n",
    "    predictions_future = model['RunResult_future'].run.future_point_predict(EndOfHistory,model['RunResult_future'].data)\n",
    "    return predictions_future\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "print('Computing predictions, production run ' + prod_id + ', development run ' + run_id)\n",
    "for model in ModelList:\n",
    "\n",
    "    # Loop that checks whether (1) this a model trained outside the main system, \n",
    "    # (2) retrieves the prediction if it exists in prediction storage,\n",
    "    # (3) if not checks whether the trained model exists, retrains if not, \n",
    "    # Then calibrates the predictions and stores them if they have not been stored before for this run.\n",
    "    # To do: set the data_preprocessing to the function in the model dictionary\n",
    "    \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        print(model['predstorename_ncal'])\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "        \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "    \n",
    "#    print('before store',model['future_df_noncalibrated'].index.names)\n",
    "        \n",
    "    model['future_df_noncalibrated'].forecasts.set_run(run_id)\n",
    "    model['future_df_noncalibrated'].forecasts.to_store(name=model['predstorename_ncal'], overwrite=True)   \n",
    "    \n",
    "#    print('after store',model['future_df_noncalibrated'].index.names)\n",
    "    \n",
    "    if calibrate_const_models:\n",
    "        print('Calibrating')\n",
    "        model['future_df_calibrated'] = model['future_df_noncalibrated'].copy()\n",
    "            \n",
    "        model['future_df_calibrated']['step_combined']=cal_pg_c(model['future_df_calibrated'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "        # Storing calibrated\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "            \n",
    "    i = i + 1\n",
    "\n",
    "print('All done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e78a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList = [] # Separate list of dictionaries for ensembles!\n",
    "\n",
    "Ensemble = {\n",
    "    'modelname':            'ensemble_cm_calib',\n",
    "    'algorithm':            [],\n",
    "    'depvar':               depvar,\n",
    "    'data_train':           [],\n",
    "    'Algorithm_text':       '',\n",
    "    'calibration_gams':     [],\n",
    "    'future_df_calibrated': [],\n",
    "}\n",
    "EnsembleList.append(Ensemble)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42948b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 753, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1004, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 683, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: could not receive data from server: Operation timed out\n",
      "SSL SYSCALL error: Operation timed out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm_ensemble=ViewsMetadata().with_name('cm_genetic_ensemble_f'+str(EndOfHistory)).fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3cc1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_run_id=int(cm_ensemble['runs_id'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5e4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_45_cm_ensemble_genetic_calib.parquet\n",
      "pr_45_cm_ensemble_genetic_test.parquet\n",
      "pr_45_cm_genetic_ensemble_f508.parquet\n"
     ]
    }
   ],
   "source": [
    "cm_predictions_calib = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_calib')\n",
    "cm_predictions_test = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_test')\n",
    "cm_predictions_future = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_genetic_ensemble_f'+str(EndOfHistory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61dd6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepcols=['step_pred_' + str(step) for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56c18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding fatalities002_pgm_conflictlong_lgbm\n",
      "adding fatalities002_pgm_conflictlong_hurdle_lgbm\n",
      "adding fatalities002_pgm_escwa_drought_hurdle_lgbm\n",
      "adding fatalities002_pgm_escwa_drought_lgbm\n",
      "adding fatalities002_pgm_natsoc_hurdle_lgbm\n",
      "adding fatalities002_pgm_natsoc_lgbm\n",
      "adding fatalities002_pgm_broad_hurdle_lgbm\n",
      "adding fatalities002_pgm_broad_lgbm\n",
      "adding fatalities002_pgm_conflict_history_xgb\n",
      "adding fatalities002_pgm_conflict_treelag_hurdle\n",
      "adding fatalities002_pgm_conflict_sptime_dist_hurdle\n",
      " .    "
     ]
    }
   ],
   "source": [
    "n_models = len(ModelList)\n",
    "\n",
    "targetcalib=ModelList[0]['predictions_calib_df'][depvar]\n",
    "targettest=ModelList[0]['predictions_test_df'][depvar]\n",
    "\n",
    "valscalib=ModelList[0]['predictions_calib_df'][stepcols].values.copy()\n",
    "valstest=ModelList[0]['predictions_test_df'][stepcols].values.copy()\n",
    "valsfuture=ModelList[0]['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "trimmed_calib=ModelList[0]['predictions_calib_df'][stepcols].copy()\n",
    "index_calib=trimmed_calib.index\n",
    "columns_calib=trimmed_calib.columns\n",
    "\n",
    "trimmed_test=ModelList[0]['predictions_test_df'][stepcols].copy()\n",
    "index_test=trimmed_test.index\n",
    "columns_test=trimmed_test.columns\n",
    "\n",
    "trimmed_future=ModelList[0]['future_df_noncalibrated'].copy()\n",
    "index_future=trimmed_future.index\n",
    "columns_future=trimmed_future.columns\n",
    "\n",
    "for model in ModelList[1:]:\n",
    "    print('adding',model['modelname'])\n",
    "\n",
    "    valscalib+=model['predictions_calib_df'][stepcols].values.copy()\n",
    "    valstest+=model['predictions_test_df'][stepcols].values.copy()\n",
    "    valsfuture+=model['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "    valscalib/=n_models\n",
    "    valstest/=n_models\n",
    "    valsfuture/=n_models\n",
    "\n",
    "    Ensemble['predictions_calib_df']=pd.DataFrame(data=valscalib, index=index_calib, columns=columns_calib)\n",
    "    Ensemble['predictions_test_df']=pd.DataFrame(data=valstest, index=index_test, columns=columns_test)\n",
    "    Ensemble['predictions_future_df']=pd.DataFrame(data=valsfuture, index=index_future, columns=columns_future)\n",
    "    \n",
    "df_pg_id_c_id=fetch_df_pg_id_c_id()\n",
    "    \n",
    "for col in stepcols:\n",
    "\n",
    "    thisstep=int(''.join([''+str(f) for f in filter(str.isdigit, col)]))\n",
    "    thismonth = EndOfHistory + thisstep\n",
    "\n",
    "    Ensemble['predictions_calib_df'][col]=calibrate_pg_with_c(Ensemble['predictions_calib_df'],cm_predictions_calib,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "\n",
    "    Ensemble['predictions_test_df'][col]=calibrate_pg_with_c(Ensemble['predictions_test_df'],cm_predictions_test,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "    \n",
    "future_calib=calibrate_pg_with_c(Ensemble['predictions_future_df'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "    \n",
    "Ensemble['predictions_future_df']['step_combined']=future_calib['step_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "697f99bb-01ba-46a2-a506-5d3ea80104b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modelname', 'algorithm', 'depvar', 'queryset', 'data_train', 'level', 'preprocessing', 'description', 'long_description', 'predstore_calib', 'predstore_test', 'predictions_calib_df', 'predictions_test_df', 'predictions_future_df', 'predstorename_ncal', 'predstorename_cal', 'future_df_noncalibrated'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelList[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'][depvar]=targetcalib\n",
    "Ensemble['predictions_test_df'][depvar]=targettest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08ccc4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 753, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1004, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 683, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: could not receive data from server: Operation timed out\n",
      "SSL SYSCALL error: Operation timed out\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 753, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1004, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 683, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: could not receive data from server: Operation timed out\n",
      "SSL SYSCALL error: Operation timed out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + Ensemble['modelname'] + '_calib'\n",
    "Ensemble['predictions_calib_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_calib_df'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + Ensemble['modelname'] + '_test'\n",
    "Ensemble['predictions_test_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_test_df'].forecasts.to_store(name=predstore_test, overwrite = True)\n",
    "predstore_future = level +  '_' + Ensemble['modelname'] + '_f'+str(EndOfHistory)\n",
    "Ensemble['predictions_future_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_future_df'].forecasts.to_store(name=predstore_future, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355ad4d",
   "metadata": {},
   "source": [
    "# Use ensemble predictions for test partition to create categorical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48672578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df=Ensemble['predictions_test_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17be8760-152e-4c05-a98a-ddcaa964c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>step_pred_1</th>\n",
       "      <th>step_pred_2</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>...</th>\n",
       "      <th>step_pred_28</th>\n",
       "      <th>step_pred_29</th>\n",
       "      <th>step_pred_30</th>\n",
       "      <th>step_pred_31</th>\n",
       "      <th>step_pred_32</th>\n",
       "      <th>step_pred_33</th>\n",
       "      <th>step_pred_34</th>\n",
       "      <th>step_pred_35</th>\n",
       "      <th>step_pred_36</th>\n",
       "      <th>ln_ged_sb_dep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>priogrid_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">445</th>\n",
       "      <th>62356</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79599</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79600</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79601</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80317</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">492</th>\n",
       "      <th>190496</th>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.054839</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029498</td>\n",
       "      <td>0.028645</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.029486</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>0.045102</td>\n",
       "      <td>0.054775</td>\n",
       "      <td>0.060249</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190507</th>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190508</th>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190510</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.017565</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190511</th>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629280 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      step_pred_1  step_pred_2  step_pred_3  step_pred_4  \\\n",
       "month_id priogrid_id                                                       \n",
       "445      62356           0.000030     0.000085     0.000062     0.000046   \n",
       "         79599           0.000011     0.000012     0.000030     0.000018   \n",
       "         79600           0.000011     0.000011     0.000030     0.000019   \n",
       "         79601           0.000012     0.000012     0.000034     0.000018   \n",
       "         80317           0.000011     0.000010     0.000021     0.000017   \n",
       "...                           ...          ...          ...          ...   \n",
       "492      190496          0.002048     0.003476     0.015028     0.003931   \n",
       "         190507          0.000319     0.000794     0.001079     0.001704   \n",
       "         190508          0.000407     0.000817     0.001355     0.001839   \n",
       "         190510          0.000364     0.000980     0.001599     0.002295   \n",
       "         190511          0.000382     0.001178     0.001753     0.002041   \n",
       "\n",
       "                      step_pred_5  step_pred_6  step_pred_7  step_pred_8  \\\n",
       "month_id priogrid_id                                                       \n",
       "445      62356           0.000040     0.000067     0.000060     0.000072   \n",
       "         79599           0.000018     0.000044     0.000032     0.000038   \n",
       "         79600           0.000016     0.000044     0.000032     0.000039   \n",
       "         79601           0.000016     0.000044     0.000031     0.000037   \n",
       "         80317           0.000018     0.000034     0.000031     0.000038   \n",
       "...                           ...          ...          ...          ...   \n",
       "492      190496          0.003679     0.012142     0.021094     0.054839   \n",
       "         190507          0.001509     0.001180     0.001462     0.000979   \n",
       "         190508          0.001838     0.001358     0.001377     0.000906   \n",
       "         190510          0.001868     0.001230     0.001547     0.000913   \n",
       "         190511          0.002091     0.001424     0.001842     0.001088   \n",
       "\n",
       "                      step_pred_9  step_pred_10  ...  step_pred_28  \\\n",
       "month_id priogrid_id                             ...                 \n",
       "445      62356           0.000023      0.000060  ...      0.000381   \n",
       "         79599           0.000019      0.000032  ...      0.000133   \n",
       "         79600           0.000020      0.000032  ...      0.000130   \n",
       "         79601           0.000017      0.000032  ...      0.000114   \n",
       "         80317           0.000022      0.000033  ...      0.000144   \n",
       "...                           ...           ...  ...           ...   \n",
       "492      190496          0.047354      0.013467  ...      0.029498   \n",
       "         190507          0.001615      0.001213  ...      0.010124   \n",
       "         190508          0.001818      0.001327  ...      0.010382   \n",
       "         190510          0.002050      0.001457  ...      0.011920   \n",
       "         190511          0.002077      0.001646  ...      0.015361   \n",
       "\n",
       "                      step_pred_29  step_pred_30  step_pred_31  step_pred_32  \\\n",
       "month_id priogrid_id                                                           \n",
       "445      62356            0.000162      0.000382      0.000153      0.000140   \n",
       "         79599            0.000148      0.000209      0.000098      0.000079   \n",
       "         79600            0.000150      0.000203      0.000098      0.000078   \n",
       "         79601            0.000105      0.000186      0.000098      0.000070   \n",
       "         80317            0.000162      0.000220      0.000107      0.000088   \n",
       "...                            ...           ...           ...           ...   \n",
       "492      190496           0.028645      0.023755      0.026663      0.029486   \n",
       "         190507           0.014279      0.017490      0.018148      0.015178   \n",
       "         190508           0.016120      0.018631      0.016765      0.016060   \n",
       "         190510           0.016441      0.020141      0.018746      0.017974   \n",
       "         190511           0.015449      0.019240      0.022460      0.017025   \n",
       "\n",
       "                      step_pred_33  step_pred_34  step_pred_35  step_pred_36  \\\n",
       "month_id priogrid_id                                                           \n",
       "445      62356            0.000352      0.000144      0.000233      0.000379   \n",
       "         79599            0.000163      0.000114      0.000144      0.000200   \n",
       "         79600            0.000165      0.000119      0.000155      0.000185   \n",
       "         79601            0.000151      0.000111      0.000177      0.000153   \n",
       "         80317            0.000175      0.000119      0.000206      0.000208   \n",
       "...                            ...           ...           ...           ...   \n",
       "492      190496           0.049908      0.045102      0.054775      0.060249   \n",
       "         190507           0.019005      0.015882      0.008130      0.020817   \n",
       "         190508           0.019687      0.018085      0.008737      0.020357   \n",
       "         190510           0.025237      0.018007      0.008321      0.017565   \n",
       "         190511           0.023846      0.019390      0.008906      0.018860   \n",
       "\n",
       "                      ln_ged_sb_dep  \n",
       "month_id priogrid_id                 \n",
       "445      62356                  0.0  \n",
       "         79599                  0.0  \n",
       "         79600                  0.0  \n",
       "         79601                  0.0  \n",
       "         80317                  0.0  \n",
       "...                             ...  \n",
       "492      190496                 0.0  \n",
       "         190507                 0.0  \n",
       "         190508                 0.0  \n",
       "         190510                 0.0  \n",
       "         190511                 0.0  \n",
       "\n",
       "[629280 rows x 37 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble['predictions_test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbba3611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_pred_1</th>\n",
       "      <th>step_pred_2</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>...</th>\n",
       "      <th>step_pred_30</th>\n",
       "      <th>step_pred_31</th>\n",
       "      <th>step_pred_32</th>\n",
       "      <th>step_pred_33</th>\n",
       "      <th>step_pred_34</th>\n",
       "      <th>step_pred_35</th>\n",
       "      <th>step_pred_36</th>\n",
       "      <th>ln_ged_sb_dep</th>\n",
       "      <th>ged_gte_25</th>\n",
       "      <th>ged_multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061167</td>\n",
       "      <td>0.075948</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.084267</td>\n",
       "      <td>0.083820</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.092823</td>\n",
       "      <td>0.091424</td>\n",
       "      <td>0.109143</td>\n",
       "      <td>0.091078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136860</td>\n",
       "      <td>0.138508</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>0.126835</td>\n",
       "      <td>0.133745</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.130821</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.333112</td>\n",
       "      <td>0.385849</td>\n",
       "      <td>0.406256</td>\n",
       "      <td>0.418138</td>\n",
       "      <td>0.397943</td>\n",
       "      <td>0.465317</td>\n",
       "      <td>0.439485</td>\n",
       "      <td>0.449475</td>\n",
       "      <td>0.529336</td>\n",
       "      <td>0.447131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534171</td>\n",
       "      <td>0.541955</td>\n",
       "      <td>0.524844</td>\n",
       "      <td>0.504415</td>\n",
       "      <td>0.522710</td>\n",
       "      <td>0.519027</td>\n",
       "      <td>0.512169</td>\n",
       "      <td>0.207899</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.130805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.001903</td>\n",
       "      <td>-0.040460</td>\n",
       "      <td>-0.258168</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>0.036383</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.036571</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.207209</td>\n",
       "      <td>8.010147</td>\n",
       "      <td>8.457104</td>\n",
       "      <td>9.254678</td>\n",
       "      <td>9.160367</td>\n",
       "      <td>9.013112</td>\n",
       "      <td>8.845149</td>\n",
       "      <td>9.117676</td>\n",
       "      <td>10.394057</td>\n",
       "      <td>9.014327</td>\n",
       "      <td>...</td>\n",
       "      <td>9.394703</td>\n",
       "      <td>8.870220</td>\n",
       "      <td>9.103304</td>\n",
       "      <td>9.433605</td>\n",
       "      <td>9.312959</td>\n",
       "      <td>9.523703</td>\n",
       "      <td>9.413598</td>\n",
       "      <td>7.817223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step_pred_1    step_pred_2    step_pred_3    step_pred_4  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.061167       0.075948       0.082473       0.084267   \n",
       "std         0.333112       0.385849       0.406256       0.418138   \n",
       "min         0.000003       0.000009      -0.001903      -0.040460   \n",
       "25%         0.000156       0.000284       0.000413       0.000366   \n",
       "50%         0.000747       0.001184       0.001533       0.001637   \n",
       "75%         0.005054       0.007676       0.008772       0.009616   \n",
       "max         8.207209       8.010147       8.457104       9.254678   \n",
       "\n",
       "         step_pred_5    step_pred_6    step_pred_7    step_pred_8  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.083820       0.099157       0.092823       0.091424   \n",
       "std         0.397943       0.465317       0.439485       0.449475   \n",
       "min        -0.258168      -0.001175       0.000011       0.000018   \n",
       "25%         0.000460       0.000465       0.000546       0.000625   \n",
       "50%         0.001912       0.002001       0.002189       0.002350   \n",
       "75%         0.010970       0.011350       0.012623       0.013249   \n",
       "max         9.160367       9.013112       8.845149       9.117676   \n",
       "\n",
       "         step_pred_9   step_pred_10  ...   step_pred_30   step_pred_31  \\\n",
       "count  629280.000000  629280.000000  ...  629280.000000  629280.000000   \n",
       "mean        0.109143       0.091078  ...       0.136860       0.138508   \n",
       "std         0.529336       0.447131  ...       0.534171       0.541955   \n",
       "min         0.000014       0.000019  ...       0.000063       0.000077   \n",
       "25%         0.000757       0.000659  ...       0.001472       0.001519   \n",
       "50%         0.002632       0.002634  ...       0.006324       0.006799   \n",
       "75%         0.015315       0.014367  ...       0.033590       0.036144   \n",
       "max        10.394057       9.014327  ...       9.394703       8.870220   \n",
       "\n",
       "        step_pred_32   step_pred_33   step_pred_34   step_pred_35  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.136882       0.126835       0.133745       0.129337   \n",
       "std         0.524844       0.504415       0.522710       0.519027   \n",
       "min         0.000070       0.000090      -0.000292       0.000041   \n",
       "25%         0.001473       0.001606       0.001613       0.001507   \n",
       "50%         0.006638       0.006664       0.006968       0.006966   \n",
       "75%         0.036383       0.034667       0.036592       0.036571   \n",
       "max         9.103304       9.433605       9.312959       9.523703   \n",
       "\n",
       "        step_pred_36  ln_ged_sb_dep     ged_gte_25      ged_multi  \n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000  \n",
       "mean        0.130821       0.016279       0.001187       0.010920  \n",
       "std         0.512169       0.207899       0.034433       0.130805  \n",
       "min         0.000099       0.000000       0.000000       0.000000  \n",
       "25%         0.001487       0.000000       0.000000       0.000000  \n",
       "50%         0.007104       0.000000       0.000000       0.000000  \n",
       "75%         0.038573       0.000000       0.000000       0.000000  \n",
       "max         9.413598       7.817223       1.000000       4.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dichotomous version of dependent variable\n",
    "ensemble_test_df['ged_gte_25'] = ensemble_test_df['ln_ged_sb_dep'].apply(lambda x: 1 if x >= np.log1p(25) else 0)\n",
    "# Generate multiclass version for uncertainty estimation\n",
    "def ged_categorical(x):\n",
    "    if x < np.log1p(0.5):\n",
    "        return 0\n",
    "    elif x < np.log1p(10):\n",
    "        return 1\n",
    "    elif x < np.log1p(100):\n",
    "        return 2\n",
    "    elif x < np.log1p(1000):\n",
    "        return 3\n",
    "    else :\n",
    "        return 4\n",
    "\n",
    "ensemble_test_df['ged_multi'] = ensemble_test_df['ln_ged_sb_dep'].apply(ged_categorical)\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b7a17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ac2300a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ensemble_test_df['ln_ged_sb_dep'],ensemble_test_df['ged_multi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61e85509-4aaf-4106-909a-691e4ed34851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in steps:\n",
    "    if ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum() != 0:\n",
    "        print('****WARNING***** - detected',ensemble_test_df[f'step_pred_{step}'].isnull().sum().sum(),'Nan(s) in column step_pred_'+str(step))\n",
    "        print('Replacing with zeros')\n",
    "        ensemble_test_df[f'step_pred_{step}']=ensemble_test_df[f'step_pred_{step}'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93d86f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/miniconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_34539/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_pred_1</th>\n",
       "      <th>step_pred_2</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>...</th>\n",
       "      <th>multi_0_step_35_logit</th>\n",
       "      <th>multi_1_step_35_logit</th>\n",
       "      <th>multi_2_step_35_logit</th>\n",
       "      <th>multi_3_step_35_logit</th>\n",
       "      <th>multi_4_step_35_logit</th>\n",
       "      <th>multi_0_step_36_logit</th>\n",
       "      <th>multi_1_step_36_logit</th>\n",
       "      <th>multi_2_step_36_logit</th>\n",
       "      <th>multi_3_step_36_logit</th>\n",
       "      <th>multi_4_step_36_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>6.292800e+05</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>6.292800e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061167</td>\n",
       "      <td>0.075948</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.084267</td>\n",
       "      <td>0.083820</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.092823</td>\n",
       "      <td>0.091424</td>\n",
       "      <td>0.109143</td>\n",
       "      <td>0.091078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991996</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>6.369305e-06</td>\n",
       "      <td>0.991997</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>6.361978e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.333112</td>\n",
       "      <td>0.385849</td>\n",
       "      <td>0.406256</td>\n",
       "      <td>0.418138</td>\n",
       "      <td>0.397943</td>\n",
       "      <td>0.465317</td>\n",
       "      <td>0.439485</td>\n",
       "      <td>0.449475</td>\n",
       "      <td>0.529336</td>\n",
       "      <td>0.447131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>1.228699e-04</td>\n",
       "      <td>0.033743</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1.080814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.001903</td>\n",
       "      <td>-0.040460</td>\n",
       "      <td>-0.258168</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>5.813771e-07</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>8.738032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995331</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>5.826412e-07</td>\n",
       "      <td>0.995292</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>8.755380e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995465</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>5.873703e-07</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>8.825959e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995489</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>6.136931e-07</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>9.231976e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.207209</td>\n",
       "      <td>8.010147</td>\n",
       "      <td>8.457104</td>\n",
       "      <td>9.254678</td>\n",
       "      <td>9.160367</td>\n",
       "      <td>9.013112</td>\n",
       "      <td>8.845149</td>\n",
       "      <td>9.117676</td>\n",
       "      <td>10.394057</td>\n",
       "      <td>9.014327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995496</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.425560</td>\n",
       "      <td>0.138729</td>\n",
       "      <td>1.171569e-02</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>0.455719</td>\n",
       "      <td>0.421536</td>\n",
       "      <td>0.129768</td>\n",
       "      <td>8.819344e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step_pred_1    step_pred_2    step_pred_3    step_pred_4  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.061167       0.075948       0.082473       0.084267   \n",
       "std         0.333112       0.385849       0.406256       0.418138   \n",
       "min         0.000003       0.000009      -0.001903      -0.040460   \n",
       "25%         0.000156       0.000284       0.000413       0.000366   \n",
       "50%         0.000747       0.001184       0.001533       0.001637   \n",
       "75%         0.005054       0.007676       0.008772       0.009616   \n",
       "max         8.207209       8.010147       8.457104       9.254678   \n",
       "\n",
       "         step_pred_5    step_pred_6    step_pred_7    step_pred_8  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.083820       0.099157       0.092823       0.091424   \n",
       "std         0.397943       0.465317       0.439485       0.449475   \n",
       "min        -0.258168      -0.001175       0.000011       0.000018   \n",
       "25%         0.000460       0.000465       0.000546       0.000625   \n",
       "50%         0.001912       0.002001       0.002189       0.002350   \n",
       "75%         0.010970       0.011350       0.012623       0.013249   \n",
       "max         9.160367       9.013112       8.845149       9.117676   \n",
       "\n",
       "         step_pred_9   step_pred_10  ...  multi_0_step_35_logit  \\\n",
       "count  629280.000000  629280.000000  ...          629280.000000   \n",
       "mean        0.109143       0.091078  ...               0.991996   \n",
       "std         0.529336       0.447131  ...               0.034523   \n",
       "min         0.000014       0.000019  ...               0.014414   \n",
       "25%         0.000757       0.000659  ...               0.995331   \n",
       "50%         0.002632       0.002634  ...               0.995465   \n",
       "75%         0.015315       0.014367  ...               0.995489   \n",
       "max        10.394057       9.014327  ...               0.995496   \n",
       "\n",
       "       multi_1_step_35_logit  multi_2_step_35_logit  multi_3_step_35_logit  \\\n",
       "count          629280.000000          629280.000000          629280.000000   \n",
       "mean                0.005320               0.002458               0.000219   \n",
       "std                 0.019015               0.013313               0.002339   \n",
       "min                 0.003244               0.001203               0.000057   \n",
       "25%                 0.003248               0.001205               0.000057   \n",
       "50%                 0.003265               0.001212               0.000057   \n",
       "75%                 0.003358               0.001251               0.000060   \n",
       "max                 0.443783               0.425560               0.138729   \n",
       "\n",
       "       multi_4_step_35_logit  multi_0_step_36_logit  multi_1_step_36_logit  \\\n",
       "count           6.292800e+05          629280.000000          629280.000000   \n",
       "mean            6.369305e-06               0.991997               0.005320   \n",
       "std             1.228699e-04               0.033743               0.018752   \n",
       "min             5.813771e-07               0.013805               0.003240   \n",
       "25%             5.826412e-07               0.995292               0.003244   \n",
       "50%             5.873703e-07               0.995438               0.003262   \n",
       "75%             6.136931e-07               0.995464               0.003363   \n",
       "max             1.171569e-02               0.995470               0.455719   \n",
       "\n",
       "       multi_2_step_36_logit  multi_3_step_36_logit  multi_4_step_36_logit  \n",
       "count          629280.000000          629280.000000           6.292800e+05  \n",
       "mean                0.002458               0.000219           6.361978e-06  \n",
       "std                 0.012878               0.002262           1.080814e-04  \n",
       "min                 0.001227               0.000062           8.738032e-07  \n",
       "25%                 0.001229               0.000062           8.755380e-07  \n",
       "50%                 0.001236               0.000063           8.825959e-07  \n",
       "75%                 0.001279               0.000065           9.231976e-07  \n",
       "max                 0.421536               0.129768           8.819344e-03  \n",
       "\n",
       "[8 rows x 220 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model to transform predictions from  fatalities to (1) dichotomous and (2) multiclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dichotomous_classifiers = []\n",
    "multi_classifiers = []\n",
    "for step in steps:\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Dichotomous\n",
    "    y_dich = np.array(ensemble_test_df['ged_gte_25']).reshape(-1, 1)\n",
    "    dich_clf = LogisticRegression(random_state=0).fit(X, y_dich)\n",
    "    dichotomous_classifiers.append(dich_clf)\n",
    "    p_dich = dich_clf.predict_proba(X)\n",
    "    ensemble_test_df['dich_step_{step}_logit'] = p_dich[:,1].ravel()\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    p_multi = multi_clf.predict_proba(X)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5cb221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList[0]['future_df_dichotomous'] = EnsembleList[0]['predictions_future_df'].copy() # Copy from baseline\n",
    "\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "#    weightcol = 'step_pred_' + str(step)\n",
    "#    weights = np.array(pd.DataFrame(i_weights_df[weightcol]))\n",
    "#    EnsembleList[0]['future_df_calibrated'].loc[month] = ConstituentModels_df_w.loc[month].dot(weights).values\n",
    "    x_d = np.array(EnsembleList[0]['predictions_future_df'].loc[month]).reshape(-1,1)\n",
    "    pred_step = dichotomous_classifiers[step-1].predict_proba(x_d)\n",
    "    EnsembleList[0]['future_df_dichotomous']['step_combined'].loc[month] = pred_step[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e11082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstore_future_dich = level +  '_' + EnsembleList[0]['modelname'] + '_dich_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.to_store(name=predstore_future_dich, overwrite = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854ca6b",
   "metadata": {},
   "source": [
    "# Mapping future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d298265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pgm geometries\n",
    "gdf_base = gpd.read_parquet('../Tools/geometry/pgm_geometry.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5277a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cm geometries\n",
    "gdf_c = gpd.read_parquet('../Tools/geometry/cm_geometry.parquet')\n",
    "gdf_c = gdf_c.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6faa706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_wanted_index=Datasets[0]['df']\n",
    "\n",
    "index_check(EnsembleList[0],df_with_wanted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a029ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future prediction maps, predictions, rolling\n",
    "#path = Mydropbox + 'Projects/PredictingFatalities/maps/cm_future/'\n",
    "stepstoplot=[3,5,6,8,12,18,24,36]\n",
    "#titles = [vid2date(i) for i in stepstoplot + EndOfHistory]\n",
    "\n",
    "\n",
    "df = Ensemble['predictions_future_df'].copy()\n",
    "gdf2 = gdf_base.copy()\n",
    "df = df.join(gdf2.set_index(\"priogrid_gid\"))\n",
    "gdf3 = gpd.GeoDataFrame(df, geometry=\"geom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d4f151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Mydropbox + 'Projects/PredictingFatalities/Predictions/pgm/preds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6194dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "#        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=0.7,facecolor='None')\n",
    "        \n",
    "#        m.cbar.set_ticks(standard_scale)\n",
    "#        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[29.446846321370213, 50.987309710685814, 1.1561557161401845, 18.29970129951559], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'ETHIOPIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.2,0.7,'SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.35,'S. SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.65,0.5,'SOMALIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.35,0.25,'KENYA',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Ethiopia_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e14c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-2.3019466946294584, 20.374695512438592, 1.103974761908613, 16.794164972712068], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'NIGERIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.4,0.7,'NIGER',fontdict=fontdict,color='black')\n",
    "        figure.text(0.5,0.35,'CAMEROON',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.60,'CHAD',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.4,'C.A.R.',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.60,'B. FASO',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Nigeria_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f266a",
   "metadata": {},
   "source": [
    "# Changes to 3- and 6-month forecasts, and since last actual observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d048ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data for mapping\n",
    "# Predictions now and then\n",
    "predstore_then = level +  '_' + EnsembleList[0]['modelname'] + '_f' + str(EndOfHistory-3)\n",
    "\n",
    "df_now = EnsembleList[0]['predictions_future_df'].copy()\n",
    "\n",
    "df_then=ViewsMetadata().with_name('ensemble_cm_calib_f'+str(EndOfHistory-3)).fetch()\n",
    "\n",
    "try:\n",
    "    df_then = pd.DataFrame.forecasts.read_store(run=run_id, name=predstore_then)\n",
    "except:\n",
    "    print('Trouble reading forecasts issued three months ago')\n",
    "    \n",
    "# Actuals\n",
    "\n",
    "df_lastobserved = Datasets[0]['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log of mean non-logged fatalities, past six months\n",
    "df_observed = df_lastobserved.loc[EndOfHistory]\n",
    "df_observed['ged_sb_0'] = np.expm1(df_observed['ln_ged_sb'])\n",
    "df_observed['ged_sum'] = df_observed['ged_sb_0']\n",
    "for t in [1,2,3,4,5]:\n",
    "    colname = 'ged_sb_' + str(t)\n",
    "    df_observed[colname] = np.expm1(df_lastobserved.loc[EndOfHistory-t]['ln_ged_sb'])\n",
    "    df_observed['ged_sum'] = df_observed['ged_sum'] + df_observed[colname]\n",
    "df_observed['ln_ged_sum'] = np.log1p(df_observed['ged_sum']/6)\n",
    "#df_observed.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepsForward = [\n",
    "{\n",
    "    'Step': 3,\n",
    "    'df_now': df_now.loc[EndOfHistory + 3],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 3]\n",
    "},\n",
    "{\n",
    "    'Step': 6,\n",
    "    'df_now': df_now.loc[EndOfHistory + 6],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 6]\n",
    "},\n",
    "]\n",
    "engine = sa.create_engine(source_db_path)\n",
    "#predictors_df = data_vdem_short.loc[EndOfHistory]\n",
    "#predictors_df_3m = data_vdem_short.loc[EndOfHistory-3]\n",
    "\n",
    "for s in StepsForward:\n",
    "    s['df_now'].rename(columns={'step_combined':'Now'}, inplace=True)\n",
    "    s['df_then'].rename(columns={'step_combined':'Then'}, inplace=True)\n",
    "    s['df'] = pd.concat([s['df_now'],s['df_then'],df_observed['ln_ged_sum']],axis=1)\n",
    "    s['df']['Change_in_prediction'] = s['df']['Now']-s['df']['Then']\n",
    "    s['df']['Change_since_last_observed'] = s['df']['Now']-s['df']['ln_ged_sum']\n",
    "    \n",
    "#    # Surrogate model change\n",
    "#    for sm in SurrogateModelList:\n",
    "#        if sm['Step'] == s['Step']:\n",
    "#            s['sdf'] = predictors_df[sm['Columns']]\n",
    "#            s['sdf'][sm['Predcolname']] = sm['GAM'].predict(predictors_df[sm['Columns']])\n",
    "#            s['sdf_3m'] = predictors_df_3m[sm['Columns']]\n",
    "#            s['sdf_3m'][sm['Predcolname']] = sm['GAM'].predict(predictors_df_3m[sm['Columns']])\n",
    "#            print(sm['Step'],sm['Predcolname'])\n",
    "#            dfcolname = sm['Predcolname'][:-2] + '_ch3m'\n",
    "#            s['df'][dfcolname] = s['sdf'][sm['Predcolname']] - s['sdf_3m'][sm['Predcolname']]\n",
    "    \n",
    "    s['gdf'] = gdf_base\n",
    "    s['gdf'] = s['gdf'].to_crs(4326)\n",
    "\n",
    "    s['gdf_t'] = s['df'].join(s['gdf'].set_index(\"priogrid_gid\"))\n",
    "    s['gdf'] = gpd.GeoDataFrame(s['gdf_t'], geometry=\"geom\")\n",
    "    \n",
    "    \n",
    "StepsForward[0]['gdf'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aeb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickvalues = np.array([-80,-50,-20,0,20,50,100,200,500])\n",
    "print(tickvalues)\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "print(tickvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b060b9d-2487-4c35-bfb1-32cd69107b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= Mydropbox + f'DataReleases/MonthlyUpdates/{run_id}_{prod_id}/Continuous/Ensemble/ChangeMaps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e22c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 3\n",
    "\n",
    "tickvalues=np.array([-300,-30,-3,3,30,300])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "\n",
    "tickvalues=np.sign(tickvalues)*np.log1p(np.abs(tickvalues)+1)\n",
    "#print(tickvalues)\n",
    "tickvalues = np.array([-83,-80,-50,-20,0,20,50,100,200,500])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "ticklabels[0] = \"\"\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "\n",
    "\n",
    "t0s=range(508,509) # From start of month A, to start of (but not including) month B\n",
    "bbox=\"africa_middle_east\"\n",
    "cmap='bwr'#'rainbow'\n",
    "for s in StepsForward:\n",
    "    for column in ['Change_in_prediction','Change_since_last_observed']:\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title=f\"{column}, s= {s['Step']}\",\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=s['gdf'],\n",
    "        map_scale=surrogate_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "        column=column, \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        m.cbar.set_ticks(surrogate_scale)\n",
    "        m.cbar.set_ticklabels(surrogate_scale_labels)\n",
    "\n",
    "        m.save(path+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')\n",
    "#        if WriteToOverleaf:\n",
    "#            plot.save(overleafpath+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a07b5-f89d-4ebe-91e9-ea8a8eaf9bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
